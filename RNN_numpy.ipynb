{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "RNN_numpy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/DeepLearning_2020/blob/main/RNN_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfXFYpH2Mfir"
      },
      "source": [
        "# Recurrent Neural Network\n",
        "Numpy implementation of binary addition in RNN. \n",
        "Code from https://github.com/revsic/numpy-rnn/blob/master/RNN_numpy.ipynb \n",
        "This code is in turn based on [iamtrask's github.io](https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W36CcBiZzcn"
      },
      "source": [
        "The network is trained to add two binary numbers \n",
        "\n",
        "Input: binary a and b in the form of a vector of bins, ex. [1 1 1 1 0 1 1 0]\n",
        "\n",
        "Output: binary c - predicted result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8KUde5RBMfjE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZWYrP3MfjM"
      },
      "source": [
        "## Data Generation\n",
        "\n",
        "Generate the binary array less than 256."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gWvfLXeJMfjP"
      },
      "source": [
        "BIN_DIM = 8\n",
        "INPUT_DIM = 2\n",
        "HIDDEN_DIM = 16\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "ALPHA = 0.1\n",
        "ITER_NUM = 10000\n",
        "LOG_ITER = ITER_NUM // 10\n",
        "PLOT_ITER = ITER_NUM // 200"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaAmtxRQMfjX"
      },
      "source": [
        "largest = pow(2, BIN_DIM)\n",
        "decimal = np.array([range(largest)]).astype(np.uint8).T\n",
        "binary = np.unpackbits(decimal, axis=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q47lt8giMfje"
      },
      "source": [
        "## Prepare weights and deltas\n",
        "Prepare weight and delta values to use in the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMg1IHCMfjh"
      },
      "source": [
        "# weight values\n",
        "w0 = np.random.normal(0, 1, [INPUT_DIM, HIDDEN_DIM])\n",
        "w1 = np.random.normal(0, 1, [HIDDEN_DIM, OUTPUT_DIM])\n",
        "wh = np.random.normal(0, 2, [HIDDEN_DIM, HIDDEN_DIM])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5p8hN4Mfjm"
      },
      "source": [
        "# delta values\n",
        "d0 = np.zeros_like(w0)\n",
        "d1 = np.zeros_like(w1)\n",
        "dh = np.zeros_like(wh)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "opGi39SLMfjt"
      },
      "source": [
        "errs = list()\n",
        "accs = list()\n",
        "\n",
        "error = 0\n",
        "accuracy = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItfrBiHhMfju"
      },
      "source": [
        "## Training\n",
        "Training binary addition in RNN with Backpropagation Through Time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cks-r1JzMfjw"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(out):\n",
        "    return out * (1 - out)\n",
        "\n",
        "def bin2dec(b):\n",
        "    out = 0\n",
        "    for i, x in enumerate(b[::-1]):\n",
        "        out += x * pow(2, i)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZhfVYz1Mfj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3881501-769e-411b-e59e-395d002cd865"
      },
      "source": [
        "for i in range(ITER_NUM + 1):\n",
        "    # a + b = c\n",
        "    a_dec = np.random.randint(largest / 2)\n",
        "    b_dec = np.random.randint(largest / 2)\n",
        "    c_dec = a_dec + b_dec\n",
        "    \n",
        "    a_bin = binary[a_dec]\n",
        "    b_bin = binary[b_dec]\n",
        "    c_bin = binary[c_dec]\n",
        "    \n",
        "    pred = np.zeros_like(c_bin)\n",
        "    \n",
        "    overall_err = 0 # total error in the whole calculation process.\n",
        "    \n",
        "    output_deltas = list()\n",
        "    hidden_values = list()\n",
        "    hidden_values.append(np.zeros(HIDDEN_DIM))\n",
        "    \n",
        "    future_delta = np.zeros(HIDDEN_DIM)\n",
        "    \n",
        "    # forward propagation\n",
        "    for pos in range(BIN_DIM)[::-1]:\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]]) # shape=(1, 2)\n",
        "        Y = np.array([[c_bin[pos]]]) # shape=(1, 1)\n",
        "        \n",
        "        hidden = sigmoid(np.dot(X, w0) + np.dot(hidden_values[-1], wh))\n",
        "        output = sigmoid(np.dot(hidden, w1))\n",
        "        \n",
        "        pred[pos] = np.round(output[0][0])\n",
        "        \n",
        "        # squared mean error\n",
        "        output_err = Y - output\n",
        "        output_deltas.append(output_err * deriv_sigmoid(output))\n",
        "        hidden_values.append(hidden)\n",
        "        \n",
        "        overall_err += np.abs(output_err[0])\n",
        "    \n",
        "    # backpropagation through time\n",
        "    for pos in range(BIN_DIM):\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]])\n",
        "        \n",
        "        hidden = hidden_values[-(pos + 1)]\n",
        "        prev_hidden = hidden_values[-(pos + 2)]\n",
        "        \n",
        "        output_delta = output_deltas[-(pos + 1)]\n",
        "        hidden_delta = (np.dot(future_delta, wh.T) + np.dot(output_delta, w1.T)) * deriv_sigmoid(hidden)\n",
        "        \n",
        "        d1 += np.dot(np.atleast_2d(hidden).T, output_delta)\n",
        "        dh += np.dot(np.atleast_2d(prev_hidden).T, hidden_delta)\n",
        "        d0 += np.dot(X.T, hidden_delta)\n",
        "\n",
        "        future_delta = hidden_delta \n",
        "    \n",
        "    w1 += ALPHA * d1\n",
        "    w0 += ALPHA * d0\n",
        "    wh += ALPHA * dh\n",
        "    \n",
        "    d1 *= 0\n",
        "    d0 *= 0\n",
        "    dh *= 0\n",
        "    \n",
        "    error += overall_err\n",
        "    if (bin2dec(pred) == c_dec):\n",
        "        accuracy += 1\n",
        "        \n",
        "    if (i % PLOT_ITER == 0):\n",
        "        errs.append(error / PLOT_ITER)\n",
        "        accs.append(accuracy / PLOT_ITER)\n",
        "        \n",
        "        error = 0\n",
        "        accuracy = 0\n",
        "    \n",
        "    if (i % LOG_ITER == 0):\n",
        "        print('Iter', i)\n",
        "        print(\"Error :\", overall_err)\n",
        "        print(\"Pred :\", pred)\n",
        "        print(\"True :\", c_bin)\n",
        "        print(a_dec, \"+\", b_dec, \"=\", bin2dec(pred))\n",
        "        print('----------')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0\n",
            "Error : [4.32476932]\n",
            "Pred : [1 1 1 1 1 0 1 0]\n",
            "True : [1 0 0 1 1 0 1 1]\n",
            "62 + 93 = 250\n",
            "----------\n",
            "Iter 1000\n",
            "Error : [3.79835296]\n",
            "Pred : [1 1 1 1 1 1 1 1]\n",
            "True : [1 1 1 0 1 0 0 1]\n",
            "115 + 118 = 255\n",
            "----------\n",
            "Iter 2000\n",
            "Error : [3.75233483]\n",
            "Pred : [1 0 0 0 0 0 0 0]\n",
            "True : [1 0 1 0 0 1 0 0]\n",
            "82 + 82 = 128\n",
            "----------\n",
            "Iter 3000\n",
            "Error : [4.31898949]\n",
            "Pred : [0 1 0 1 1 1 1 1]\n",
            "True : [0 1 1 0 0 0 0 0]\n",
            "85 + 11 = 95\n",
            "----------\n",
            "Iter 4000\n",
            "Error : [3.11373723]\n",
            "Pred : [0 1 0 0 0 0 0 1]\n",
            "True : [0 1 0 1 0 1 0 1]\n",
            "23 + 62 = 65\n",
            "----------\n",
            "Iter 5000\n",
            "Error : [2.56528033]\n",
            "Pred : [1 0 0 0 0 0 0 0]\n",
            "True : [1 0 1 1 0 0 0 0]\n",
            "116 + 60 = 128\n",
            "----------\n",
            "Iter 6000\n",
            "Error : [1.56371918]\n",
            "Pred : [0 1 0 1 0 0 0 1]\n",
            "True : [0 1 0 1 0 0 0 1]\n",
            "52 + 29 = 81\n",
            "----------\n",
            "Iter 7000\n",
            "Error : [0.58668388]\n",
            "Pred : [1 0 1 0 1 0 0 0]\n",
            "True : [1 0 1 0 1 0 0 0]\n",
            "88 + 80 = 168\n",
            "----------\n",
            "Iter 8000\n",
            "Error : [0.94169139]\n",
            "Pred : [1 0 1 0 1 1 0 0]\n",
            "True : [1 0 1 0 1 1 0 0]\n",
            "77 + 95 = 172\n",
            "----------\n",
            "Iter 9000\n",
            "Error : [0.53757416]\n",
            "Pred : [0 0 0 1 0 0 0 1]\n",
            "True : [0 0 0 1 0 0 0 1]\n",
            "3 + 14 = 17\n",
            "----------\n",
            "Iter 10000\n",
            "Error : [0.37197407]\n",
            "Pred : [0 1 1 0 0 1 0 1]\n",
            "True : [0 1 1 0 0 1 0 1]\n",
            "67 + 34 = 101\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIcQ6dxxMfkH"
      },
      "source": [
        "## Plot learning curve\n",
        "Plot error and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWTNNqqSMfkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e1013fc0-a9da-45a6-a970-b0d9ade522e7"
      },
      "source": [
        "plt.plot(errs, label='error')\n",
        "plt.plot(accs, label='accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f36bed43710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3iUVfbHP3dKMuk9IT0BQu+E3kUEERuK2AULupbV3XVddXWrrrprW9tPsfeGoqLIKr1Ikd5bIKQQ0nsySWbm/v64k0kCAQIkJJPcz/PMk5n3vXPfM5B857znnnuOkFKi0Wg0GvfH0NoGaDQajaZ50IKu0Wg07QQt6BqNRtNO0IKu0Wg07QQt6BqNRtNOMLXWhUNDQ2VCQkJrXV6j0Wjckk2bNuVJKcMaO9dqgp6QkMDGjRtb6/IajUbjlgghjpzsnA65aDQaTTtBC7pGo9G0E7SgazQaTTuh1WLoGo2mfVNTU0NGRgZWq7W1TXFLLBYLMTExmM3mJr9HC7pGo2kRMjIy8PPzIyEhASFEa5vjVkgpyc/PJyMjg8TExCa/T4dcNBpNi2C1WgkJCdFifhYIIQgJCTnjuxst6BqNpsXQYn72nM2/XZMFXQhhFEJsEUJ838g5TyHE50KIg0KI9UKIhDO25BxYm5LPpiMFABzOK2fX0eLzeXmNRqNpE5xJDP1+YA/g38i524BCKWVXIcS1wDPAzGaw76S8teoQmUWV9I4K4E9fbcdiMvDOrCHc/fFm8suruXpwDFGBXvSLDuDCXhHNfv1dR4sJ8fGkU4Cl2efWaDSas6FJgi6EiAEuAZ4Eft/IkMuBvzmfzwNeEUII2YLdM+ZtymDvsVIA+sUEcCS/gmvfXIeX2cgNw+L47Nd07A6Jr6eJX/98IV4expPOVW1z8MaKFAbFBzGqa+hJx5Vaa/DxMHEor4wrX/uF3lH+zL97VLN/No1Gc36w2+0YjcaTvm4MKSVSSgyGthexbqqH/iLwEOB3kvPRQDqAlNImhCgGQoC8+oOEEHOAOQBxcXFnY68LKZWQj0kK5Y4xnVmbks8Dn2/l6av6cVn/KB6f1ovNRwq5/q31/G/XMWKDvdl1tJgrBkbjbzGzZE82Ty7cw5D4YHLLqli6NweAqwfH8NT0vpiN6j/rvTWHWbwnh/3ZpeSUVtEtwheDEFTbHGxJK2JnZjF9ogOotjnYkVnEoLgghPP8bz/dQnm1jVdvGIS/pempRxqNpnn46KOPeOmll6iurmbYsGG89tprBAQEcOedd7J48WJeffVVpkyZ0uD1hg0beOeddwC4/fbbeeCBB0hNTWXy5MkMGzaMTZs2sXDhQuLj41v5053IaQVdCDENyJFSbhJCjD+Xi0kp5wJzAZKTk8/Je3dISUyQF3+c3AOAi/tGMqFHOBaz+na1mI0M7xxCbLAXb60+RFp+BSVWG0//uBd/i5ljJVbigr2ZvyWTaruDv13ai9yyKl5dloLDIXl2Rn9WHczjbwt20y3Cl9FJocQFe/Plxgwyiyp5anpf/rFgNx+sTeXvl/XhNx9vYvm+XF6+biBT+0byuy+2smjXMYwGwY1vreeBC5OwmIzszy5lar9Iwv10qEbTcfj7gl3sPlrSrHP2ivLnr5f2Pun5PXv28Pnnn7NmzRrMZjN33303H3/8MeXl5QwbNoznnnsOoMHrTZs28e6777J+/XqklAwbNoxx48YRFBTEgQMHeP/99xk+fHizfo7mpCke+ijgMiHEVMAC+AshPpJS3lhvTCYQC2QIIUxAAJDf7NbWwyHlCavAtWJei8EguHpQLC8s3o+vp4k3bhrMmoN5WGvsdA7zZfaoBPLKqskusTIoLggAT5OR53/eT0W1nf3ZpSSEeLPgvtF4mtTcc8Z2Zn92GQNiA9meUcy8Teks3ZtDfnk1wT4e/N/yFNILK/hhexaPTu1BlzBf7vt0C7e+V1eIbO7KQ7wwcwAD4gKprLZjNhrw8dRbAjSa5mTJkiVs2rSJIUOGAFBZWUl4eDhGo5GrrrrKNa7+69WrV3PllVfi4+MDwPTp01m1ahWXXXYZ8fHxbVrMoQmCLqV8BHgEwOmhP3icmAN8B9wCrAWuBpa2ZPxc2QWGJqT1zEiOYcH2ozx4UTcm9+7E5N6dGpyPDvQiOtDL9fq+C7piNhp4YfF+qm0O3p09xCXmAN4eJgbEBgJw17jO5JZWEeBlZmrfThSUV/PHedvZc6yEqX07cceYzggh2Pz4JDanFVJlc+DraeK+T7Ywc+4615wxQV6s+OMEVu7P5afdx3jiir4YDTrdS9N+OJUn3VJIKbnlllt46qmnGhx/9tlnG8TJLRbLaePmgEvk2zJn7RYKIf4BbJRSfge8DXwohDgIFADXNpN9J8UhJU3RvKhALxb/flyT5xVC8JvxXbi4Tyf2HithQvfwk46ND/HhrVuSXa9r7A5eXHyAaruDJ67o67qDsJiNjOxSt9j64/1jWHkgl8N55WSXWPl0QzobDhfw4uL9bMsopmekP51DfVmyN5tbRyUSG+zdZPs1Go1i4sSJXH755fzud78jPDycgoICSktLT/meMWPGMGvWLB5++GGklMyfP58PP/zwPFl87pyRoEsplwPLnc//Uu+4FZjRnIadDkcTPfSzJSHUh4TQM/tGNhsNfDZnOAaDINjH46Tjgnw8uHxANAAV1Ta+2XKUl5ceYFtGMb6eJp5auJdquwO7Q/LRuiM8eWVfrkmOZcG2o6QVVJAU7sukXhF604ZGcwp69erFE088wUUXXYTD4cBsNvPqq6+e8j2DBg1i1qxZDB06FFCLogMHDiQ1NfU8WHzuiBaOjJyU5ORkeS4NLkY/s5ShicE8f82AZrSqdbjnk838sD0Lo0HwxZ3DufntDQxNDOaxab14bP5ONqcVMntUIq+vSHG957/XDnB9KWg0bZE9e/bQs2fP1jbDrWns31AIsUlKmdzY+LaXSNlEmhpDdwcu7RcJwNikUAbHB7P+zxfyzqwhdAnz5b/XDcDH08TrK1IY3z2MnX+fzKC4QB7/ZifHinUVO41GU4fbCnpTY+juwPju4YxJCmXO2C4A+HqaXOGUcD8Lr1w3kCsGRPHydQPx9TTx3DUDqLY7eGbR3tY0W6PRtDHcNldOCXr7UHSL2ciHtw076fmRXUMZWW8Ha2KoD9cOiePj9Ud4ZGoPndOu0WgAt/bQO3Ylt1tGJlBjl3yyPg2A/LIqnlm0l79+u5N31xwmq7iylS3UaDTnG7f10GU7CrmcDYmhPozvHsbH69OYPSqRh+ZtZ9m+HHw9TZRYbTz5wx7enT2EMUlhrW2qRqM5T7i1h95eQi5ny93ju1JYXs2k51ewZG8Oj07tyfa/TWbJH8aRGOrD77/YRn5ZVWubqdFozhNuLOgd20MHGJoYzPu3DqWy2k5yfBCzR6lWVV3CfHnpuoEUV9bw6PwdrWylRqM5X7htyMXhOLGWS0dkVNdQVj40AYvZ2KBcQM9Ifx64MIl/L9rHyv25jO2mQy8aTUths9kwmVpfTt3WQ29PeejnSpCPR6P13m8bnUhCiDd/X7CLGrujFSzTaFqfK664gsGDB9O7d2/mzp0LwKJFixg0aBD9+/dn4sSJAJSVlTF79mz69u1Lv379+OqrrwDw9fV1zTVv3jxmzZoFwKxZs7jrrrsYNmwYDz30EBs2bGDEiBEMHDiQkSNHsm/fPkDVWH/wwQfp06cP/fr14+WXX2bp0qVcccUVrnl//vlnrrzyynP+rK3/lXKW6JDL6fE0GXn44h7c9dFmVu7PZWLP5u/cpNE0iR8fhmPNHP7r1Bcufvq0w9555x2Cg4OprKxkyJAhXH755dxxxx2sXLmSxMRECgpU+8p//vOfBAQEsGOHsrOwsPC0c2dkZPDLL79gNBopKSlh1apVmEwmFi9ezKOPPspXX33F3LlzSU1NZevWrZhMJgoKCggKCuLuu+8mNzeXsLAw3n33XW699dZz+/fArQVdlcfVnJqx3cIwGgRb04u0oGs6JC+99BLz588HID09nblz5zJ27FgSE9WaU3BwMACLFy/ms88+c70vKCjotHPPmDHDVamxuLiYW265hQMHDiCEoKamxjXvXXfd5QrJ1F7vpptu4qOPPmL27NmsXbuWDz744Jw/qxsLukRHXE6Pt4eJbhF+bE0vAlS+up/FjIfJbaNtGnekCZ50S7B8+XIWL17M2rVr8fb2Zvz48QwYMIC9e5u+y7r+Wp3V2rDcRv2Suo8//jgTJkxg/vz5pKamMn78+FPOO3v2bC699FIsFgszZsxolhi82/5V6xh60xkQG8jW9CK2ZxSR/ORiev1lEX+at721zdJoWpzi4mKCgoLw9vZm7969rFu3DqvVysqVKzl8+DCAK+QyadKkBtUYa0MuERER7NmzB4fD4fL0T3at6GhVMO+9995zHZ80aRJvvPEGNputwfWioqKIioriiSeeYPbs2c3yed1W0HUMvekMjA2k1GrjiR/2YDEZGdElhK+3ZFBWZWtt0zSaFmXKlCnYbDZ69uzJww8/zPDhwwkLC2Pu3LlMnz6d/v37M3PmTAAee+wxCgsL6dOnD/3792fZsmUAPP3000ybNo2RI0cSGRl50ms99NBDPPLIIwwcONAl3qBK8MbFxdGvXz/69+/PJ5984jp3ww03EBsb22xVKU9bPlcIYQFWAp6oEM08KeVfjxszC/gPqhUdwCtSyrdONe+5ls/t/MgP3DOhK3+4qPtZz9FR2HeslMkvrgRUE+zpA6O5/q31vH1Lso6ra1oMXT739Nx7770MHDiQ2267rdHzLVE+twq4QErZHxgATBFCNNZY73Mp5QDn45Ri3hx09FouZ0LXcF98nGmNM4fEMjghCIvZwKoDeSeMlVLy9mpdC0ajaWkGDx7M9u3bufHG4zt6nj1N6SkqgTLnS7Pz0TpdMZzU3lXokEvTMBoEgxOCySqqJDk+CCEEwzuHsPJA7gljt2UU88/vd1NRZeO+iUmtYK1G0zHYtGlTs8/ZpBi6EMIohNgK5AA/SynXNzLsKiHEdiHEPCFEbLNaeRwO59eJXhRtOi/OHMAndwx33dWM7hrKodxy5m3KYGdmsWvcT7uOAZBeWNEqdmraF63VEa09cDb/dk0SdCmlXUo5AIgBhgoh+hw3ZAGQIKXsB/wMvN/YPEKIOUKIjUKIjbm5J3qHTcWhPfQzJtjHgzA/T9frCT3CEQIe/HIb015ezU1vryejsIKfdmcDkFagBV1zblgsFvLz87WonwVSSvLz87FYzqzXwZk2iS4SQiwDpgA76x3PrzfsLeDfJ3n/XGAuqEXRM7K0HrWCrmPoZ0+XMF9W/nECJdYaVh/I45WlB7l27joyCivxMBpIL9AxdM25ERMTQ0ZGBufivHVkLBYLMTExZ/Se0wq6ECIMqHGKuRcwCXjmuDGRUsos58vLgD1nZMUZInXIpVmIDfYGoHdUAL2jArjl3Q0AXD4giq82Z1Btc+gNSJqzxmw2u3Zjas4PTflrjQSWCSG2A7+iYujfCyH+IYS4zDnmt0KIXUKIbcBvgVktY66i1kM3aq1pNkYnhfLizAHcd0FXhnUOwSHhaNGJXrrDIamoVjm2dockLV+HZjSatkJTsly2AwMbOf6Xes8fAR5pXtNOjl4UbRku7R8FwPpDKoKWVlBBQqhPgzHzNmXwxA+7+eWRiXyzJZO/L9jF+kcvJNjH47zbq9FoGuKWPq6OobcscSEqFJNWUEF6QUWD0rvbMooosdrYklbI2pR8auySw3nlrWWqRqOph1sKunTqi85yaRki/Cx4GA2sO5TPxOdX8MT3u13njjhDLBtTC9l4RNWkSCvQgq7RtAXcUtDr0ha1orcEBoMgJsiL77dnUW1z8NH6NPZnlwKQmq/Ee8H2o2SXqH6lafk6I0ajaQu4uaC3siHtmNoMmMm9I/DxMPLED3uostk5WlSJ0SA4lKuE3SB0zrpG01ZwU0FXP3UMveVICPFGCPjTlB7MGduZlftz2XSkEIeEsUmhAHh7GBkYF0S6FnSNpk3gloIudcilxblzXBfemz2UzmG+rgbT8zZmAHDVYLXZYUBsIImhPhzRMXSNpk3glh2L6tIWW9eO9kxUoBdRgV4A9Ir0x8fDyMKdau/YyC6hXNgznIt6dyK72Mq8kiqsNXY8TQZ916TRtCJu6aHrRdHzi8loYHBCMNYaB34WE0HeZt66ZQjXJMe6Uhzf/yWVEU8tZdOR0zfW1Wg0LYNbC7rW8/PHsETV2DYhxKeBF167ePrcT/s5VmLl1vd+5WBOaavYqNF0dNxS0HUtl/NPraDHOz3yWuKcgl5td/CHSd0QAl5YfOC826fRaNw2hu4Mubjl15F70jcmgCBvM32iAxocD/HxwNvDSKivJ78Z34VtGUUczC47ySwajaYlcUtBtzt0DP1842kysuzB8fh4NvyVEULw10t7kRjqi8loIDHUh5UH8nA4JAa9aq3RnFfcUtB1HnrrEOjdeAGumUPiXM87h/lSbXNwtLiSmCDvRsdrNJqWwS2DFrqnaNsl0Vmd8fiCXW+sSOFP87aToVvbaTQthlsKui6f23bp7BT02tIAADa7g1eWHeTzjelc8NwKNqfp1EaNpiVwU0HXHnpbJczPEx8PI4fzyrnjg408/s1OtmUUUWq18dglPQn29uCv3+6ixu5ga3qR7jep0TQjTWlBZwFWAp7O8fOklH89bown8AEwGMgHZkopU5vdWie6HnrbRQhB5zBflu7NIa2gArNRYHNIDAJmDI4l1NeTBz7fyvj/LCezqJIPbxvKmKSw1jZbo2kXNMVDrwIukFL2BwYAU4QQw48bcxtQKKXsCrzAcT1Hmxudh962SQz1Ia2gApNBUGOXfLohjf6xgQR4m7l8QBTDOwdTUlkDNN7mTqPRnB2nFXSpqE0sNjsfx98nXw6873w+D5goWtB91iGXtk3twujk3p0Y3VVVZhzr9MKFEHxw6zBW/WkCAIUVNa1jpEbTDmlSDF0IYRRCbAVyUE2i1x83JBpIB5BS2oBiIKSReeYIITYKITbm5uaetdF6UbRt0y3CD4DrhsZx2+hEDAIm9YpwnfcwGQjwMuNhNFBYUd1aZmo07Y4m5aFLKe3AACFEIDBfCNFHSrnzTC8mpZwLzAVITk4+69UwXculbTO5dwRf3DmCoc5yAZsem0TQcU2khRAE+ZgpLNeCrtE0F2eU5SKlLAKWAVOOO5UJxAIIIUxAAGpxtEXQ9dDbNiajwSXmwAli7jru7aFDLhpNM3JaQRdChDk9c4QQXsAkYO9xw74DbnE+vxpYKlswH02HXNoHQd4eFOmQi0bTbDQl5BIJvC+EMKK+AL6QUn4vhPgHsFFK+R3wNvChEOIgUABc22IWAw6HXhRtDwT5mNl3TJfa1Wiai9MKupRyOzCwkeN/qffcCsxoXtNOjq7l0j4I9PagSIdcNJpmwy13iupaLu2DYG8PiiprXHdcGo3m3HBLQXfF0LWiuzWB3mbsDkmp1dbapmg07QI3FXTtobcHgpzleHUuukbTPLi1oOsYunsT7ExnLKioZtHOLKw19la2SKNxb9xS0HUtl/ZBoLcZgJX7c7nro818sTG9lS3SaNwbtxR0HXJpH9SGXJbtzQHgl4ON70U7lFvGgm1Hz5tdGo274qaCrn5qD929qd1Buj2zGIB1h/MbzXh5Z81h7v9siw7JaDSnwU17iupaLu0Bf4sJo0Fgd0g8TAaKKmrYnlnMop3HyCisoE90AHeN60JGYSUOqdra9Yz0b22zNZo2i1t66LqWS/tACEGgl4qjXzUoBoB7Pt7M6ytSWH0wj+d/2o/dIcksVDXTD+SUnXQujUbjpoKuQy7th9qwy5Q+nUgI8SazqJIbh8fxpyk9qLY7OFpUSaazCcbBbF0mQKM5FW4q6HpRtL0Q5Mx06R8TwCX9IukV6c+fp/YiPsQbgG0ZRVRUq9j5wVztoWs0p8JNBV391Hno7k+nAC+6hPkQ6O3BHyf34IffjsbLw+jqerTmYB6gmmIcyC4jLb+CL3V6o0bTKG65KKprubQfHp/WE2u1w/W69ks6ws+Cp8nAGmcq47DEYNam5PPo/B2sPphH35gAenTSC6QaTX3c1EPXi6LthXA/C3HO8Ep9DAZBQohqNg0wrlsYNodktdNj/2R92nm1U6NxB9xT0J0OnRb09k1tHN3LbHR1QPL2MDKxRzhfb86kvEoX9dJo6tOUjkWxQohlQojdQohdQoj7GxkzXghRLITY6nz8pbG5mgudh94xqI2jRwd50TXcF4vZwPVD4/jN+C6UVdn4frveParR1KcpMXQb8Acp5WYhhB+wSQjxs5Ry93HjVkkppzW/iScidfncDkF8iFPQA73w9jDx0wPjiAy0YDIIYoO9+Hl3DjOHxLWylRpN2+G0HrqUMktKudn5vBTYA0S3tGGnQqctdgwSQlXIJTrIC4C4EG/MRgNCCMYmhbHuUD41dsepptBoOhRnFEMXQiSg2tGtb+T0CCHENiHEj0KI3s1g20nRG4s6BrUhl9igExdNxySFUVZlY2t60fk2S6NpszRZ0IUQvsBXwANSypLjTm8G4qWU/YGXgW9OMsccIcRGIcTG3Nzcs7VZx9A7CJEBXrx03UBmDok94dyILiEYBKzaf/a/RxpNe6NJgi6EMKPE/GMp5dfHn5dSlkgpy5zPFwJmIURoI+PmSimTpZTJYWFhZ220ruXScbisf5SrEUZ9ArzMDIgNZOWBvFawSqNpmzQly0UAbwN7pJTPn2RMJ+c4hBBDnfM2Xty6GdAhFw2osMv2jCKKK2pa2xSNpk3QFA99FHATcEG9tMSpQoi7hBB3OcdcDewUQmwDXgKulbVudAugF0U1AGOSQnFI+CVFe+kaDTQhbVFKuRo4pXRKKV8BXmkuo06HruWiAegfG4ifp4mVB/KY1CuClNxyunfya22zNJpWwy13iupaLhoAs9HAiC4hrDqQy9M/7mXyiyt5b83h1jZLo2k13FLQdS0XTS1jkkLJKKzknTWH8beY+NuC3XoHqabD4qaCrn4atYve4RmTpLKlvMxGFt4/hh6d/Hh1WcoJ45buzebX1ILzbZ5Gc15xU0HXeegaRXyIN5N6RfDI1J7EBHlz7ZBY9mSVsO9YXXcjKSUPzdvOcz/ta0VLNZqWxy0FXeq0RY0TIQRv3pzMjcPjAZjWPwqjQfDN1kzXmJTcMvLKqknLr2gtMzWa84JbCrrDoWPomsYJ9fVkdNdQvtt61PV7su6QCrVklVipstlb0zyNpkVxT0F3eeita4embXJp/ygyiyrZc0xVqFh3SO1xkxIyCytb0zSNpkVxU0GvjaFrRdecyDBnM4zNRwqRUrLuUAGxwapi45ECHXbRtF/cUtCllNo715yUmCAvwvw82ZxWxKG8cvLKqrh6kCrwlV5QwYbDBWw6UgjA8z/v5+8LdrWmuRpNs+GWgu6QOn6uOTlCCAbHBbHpSCH/23UMgCsGRmExGziSX8Hvv9jK0z/uAWDl/lxW6oqNmnaCWwq6XUot6JpTMjg+iLSCCt5dk8rwzsHEh/gQF+zNsn05ZBRWkldWDUBBeTWFuriXpp3gloLukFLnoGtOyaD4IAByS6u4bqhqUxcX7M2h3HIA8suqACXoRRXV2B0tVktOozlvuKWgSx1y0ZyGPtH+eBgNBPt4MKVPJwDign1c50usNsqq1MMhoaRSeem5pVVc+vJqdh0tbhW7NZpzoSlNotscDodeFNWcGk+TkdmjEogN9sbTZAQgzpnpEuhtpqiihpScMtf4gopqgnw8+HJTOjsyi/n1cAG9owJaxXaN5mxxSw9dL4pqmsIjU3u6dpACdHOW1r1qUAwAB+oJemF5NVJKvvg1HYBjJVUnzLf+UD5lVbaWNFmjOSfcVNB1DF1z5ozoHMKSP4xjcm8VgjmQU1fvpaC8mvWHC0h1lgc4VtxwA1JKbhkz565zCb5G0xZpSgu6WCHEMiHEbiHELiHE/Y2MEUKIl4QQB4UQ24UQg1rGXIWUEoOOuWjOECEEXcJ8CfFVPUoPZNfz0Cuqmb85Ez9PE32i/ckqtjZ476KdKv0xu6ThcY2mLdEUD90G/EFK2QsYDtwjhOh13JiLgSTnYw7wf81q5XHokIvmXAhxNp1u6KHXsC+7lP6xgSSG+nLsOOH+cWcWALllJ4ZiNJq2wmkFXUqZJaXc7HxeCuwBoo8bdjnwgVSsAwKFEJHNbq0Th94pqjkH/C1mjAZBekElBgEeJgOFFdWkF1QQG+xFZICFY8VWV2es9IIKdmaqujD5zvx1jaYtckYxdCFEAjAQWH/cqWigfnAxgxNFHyHEHCHERiHExtzcs9+d55C6jovm7DEYBMFOLz3Yx4MQHw8yCivIL68mNtibCH8LVTYHRc4NR7XhlqRwX/K0h65pwzRZ0IUQvsBXwANSypKzuZiUcq6UMllKmRwWFnY2U9TOoz10zTkRUk/Qg7w92Jau8s7jgr2JDLAAuOLoWzOKiAv2ZkBsoBZ0TZumSYIuhDCjxPxjKeXXjQzJBGLrvY5xHmsRHHrrv+YcqV0YDfbxINjHg8wildUSG+RNJ6egHytRx9ILKogP8SbUz5P8smpXKEajaWs0JctFAG8De6SUz59k2HfAzc5sl+FAsZQyqxntbIBeFNWcK8E+ngCE+HgS5PTWQXnonfydgl6svPEj+UrQQ3w8sDkkxZW69oumbdKUnaKjgJuAHUKIrc5jjwJxAFLK14GFwFTgIFABzG5+U+vQeeiac6V+yKU2fOfnaSLQ24yvw4RBqFz04ooaiitriA/2IcxPfQnklVUT6O1xsqk1mlbjtIIupVwNnFI+pboHvae5jDodupaL5lypFfQgHw+Mzt+l2GBvhBCYjYIwP0+yiq0cKVDFvOJCvPHxUH8ueWVVdA33bR3DNZpT4J61XPSiqOYcCXbG0EPqeei1XY0AOvlbOFZi5Yhz52h8iLfrnF4Y1bRV3HTrv/bQNedGiDOGHuzj4YqhxwXXiXanAAuZRZWkOVvWxQV7E+qr3lObi15ZbSddt7TTtCHcVNB1DF1zbnQN98FoEHQN9yXY+0RBHxgXxKHcclYdyCXMzztVZjgAACAASURBVBNvDxNB3sqbzyur4mhRJVe+tobJL66kstreWh9Do2mAWwq61GmLmnOka7gfO/82mZ6R/nQJ9yXU18PVFAPg0v5RAKw7VOASeqNzQ1JmYSUzXl/LvuxSKqrt7M7StdM1bQO3FHSHQ4dcNOeOl4eqkx7hb2HjY5Ma1D+PDvRiaGIwAPH1PPcQH08W7swis6iSZ6b3A2BHRtMEvdrm4Kddx3Qeu6bFcE9B1yEXzXng8gHKS4+rtyAa6ueBtcZBQog3M5JjCPPzZHtm0wT9p93HmPPhJnY0cbxGc6a4qaBrD13T8kzrG0WvSH9GdQ11HatdTL12aBxCCPpGB7CziQJdu8Bav2yvRtOcuGXaoqqH3tpWaNo7Ad5mFt4/psGxqEAvzEbB1YNV16O+0QEs35dDRbUNb49T/zkddZYXSMnVgq5pGdxSFnUtF01rcefYzsy/e5QrhbFvdAAOCbuPnr5e3dEiVezrUG55i9qo6bi4qaDr8rma1iHIx4M+0XWLp31j1POt6UWnfa/20DUtjZsKut4pqmkbRPhb6BXpz8fr07DZHaccWyvoqfnlpx2r0ZwNbinoupaLpi3xwIVJHM4r5+stJ68YXWqtocRqo2u4LzV2SUZh5UnHas6eo0WVHfrL0i0FXXvomrbEpF4R9IsJ4L+LD5xUTGqbZYxJUhkzOuzS/FRW27ngueV8tTmjtU1pNdxW0HUMXdNWEEJw9/guZBZVsiYln2V7cxj/n2W8ufIQGw4XsP5QvquBRq2g64XR5qfUWoO1xuFKD+2IuGXaospDb20rNJo6JvQIx89i4tstmRzMLeNosZUnF+5xnZ/hTHPsFRlAiI+H9tBbAGuNujsqrOi4DUhOK+hCiHeAaUCOlLJPI+fHA98Ch52HvpZS/qM5jTwelYfuljcXmnaKp8nI1D6RfLU5A5tD8s/Le9MvJpCC8mru+WQzX2/JxGRQddZ7RPqxrYnlAjRNx2pTRdKKKqpb2ZLWoymq+B4w5TRjVkkpBzgfLSrmoHeKatomlw+IwuaQ+FtMTB8UQ//YQCb0COeSvpHYHZJOARaMBsHwxBD2ZJVQWN5xhaclsNYoQS8s77ge+mkFXUq5Eig4D7Y0GV3LRdMWGdY5hO4Rftw+pjM+nnU3v9cOVf3TowJVA42RXUMAWHco//wb2Y6pC7l03C/K5opbjBBCbBNC/CiE6H2yQUKIOUKIjUKIjbm5uWd9Me2ha9oiRoPgf78by28nJjU4PiguiP6xgfR1bkjqFxOIt4eRtVrQm5VaD71Ix9DPic1AvJSyTAgxFfgGSGpsoJRyLjAXIDk5+axriEqdtqhxI4QQfP2bka7fWbPRwJCEYH5J0YLenLhCLtpDP3uklCVSyjLn84WAWQgRepq3nRO6lovG3TAaRINU25FdQjiYU8bMN9by7prDp3inpqlUOgW9yubosF2kzlnQhRCdhPM3VQgx1Dlni7oeDoeu5aJxby7uE0mfaH/2Z5fy4bojrW1Ou6Cqpm5TV0f10k8r6EKIT4G1QHchRIYQ4jYhxF1CiLucQ64GdgohtgEvAdfKFm7JoneKatyduBBvvr9vDDcMi+dIfgVVto7pUTYn1nr/hh1V0E8bQ5dSXnea868ArzSbRU1A13LRtBeSInyxOySH88rp0cm/tc1xa2pj6NBxF0bdcneOQze40LQTksL9AN3FqDmw6pCL+wq6jqFr2gOdw3wwCDiQXdraprg99T30jrr93y0FXYdcNO0Fi9lIfIgPB3LqPPScEis3vb2eOz7YCECJtcZVS11zcqw1DjyMStKKOuguXDctzqUXRTXth6RwX/Y7PfScUiuXvLya3NIqADIKK/jn97tZf7iA5Q+OJ9DbozVNbdNYbXb8vUxUVNu1h+5O6J2imvZEUoQvqfkVVNscfPFrOrmlVbxy/UAAPlx7hMV7ciiqqOHlpQdb2dK2jbXGjqfJSJC3R4ct0OWmgq5ruWjaD90i/LA7JPuzS/liYwYjOocwrV8UvSL9mbvqEHaHZExSKB+sTSU1T9dRPxlVNQ4sZgOB3ma9KOpOSAlGreiadsKQhGC8PYzc/v5G0goqmDlEFfO6uE8npIShicE8N6M/DgnzNnXcbjynw1pjx2JWHroOubgReuu/pj0RFejFazcMIresCj+LiSl9OgEwrX8UZqPg5hHxhPtbGBwfxNK9OWc0t5SSsipbS5jd5rDalKAHept1yMWd0HnomvbG+O7hvDNrCC9dOxCL2QhAYqgPG/88iWn9ogC4oEc4u7NKyCpuesbL15szGfLEYgpOkvVxKLeMjML20bLN6gy5aA/dzbDrWi6adsi4bmFM6BHe4FiAt9n1fKLz3LK9daWniyqqmfjccu7/bAs5pdYT5vxu21Eqa+xsTS9s9Jq3vb+Rx77Z2RzmtzrWGjsWk5EALzMl1hocjhatQNImccu0RV0+V9MR6RruS0yQF+//ksqmI4VcNTiaRTuPcTivnPTCSlYdyOP7+0a7GmmUV9lY6yzRuy29mAt6RDSYL72ggsN55Q025LgztTF0P4sJKaGixo6vp1tK3Fnjlh66jqFrOiJCCKb1i2JfdimLdmZx09sb+GjdEW4aHs+Ce0djrbHz+y+2Ynd6pqsO5FFtV5ttdmSe2MN09cE8ALKKre0izm6tceBpNuBnUXc1pdaOF3ZxU0HXeeiajslDk7uz6++TWffoRMZ3C6OTv4XfT+pO905+/P2y3qw7VMDzP+8DYMmebPwsJqb27cT2jCKOL4JaK+igYunuTpWtzkMHKLW6/5fUmeKW9yM6D13TUTEYhKtf6duzhmCzOzA5t7tfPTiGTUcKeXVZCql5FSzZm82kXp0YFB/EN1uPcrTYSid/1aja4ZD8cjCP/rGBbEsvIiW3jH4xga350c4Za40Di6m+oHc8D90tBV3XctFoFLViDiok8+SVfSmurOGHHVlM6d2JR6f2ILtElRG4/9Mt7M8u5dt7R1NqraGwooZHpsaxM7OYlBz337CkYuh1IZcS7aG7B7qWi0bTOEaD4JXrB3GsxEq0c3E0yNsDk0Gw8UghQsAbK1Ior1biN7FHOPEh3hx0Fgc7nFfOjW+t54PbhtIlzJeyKptbLCza7A5sDonFbMTf6aGXaUE/ESHEO8A0IEdK2aeR8wL4LzAVqABmSSk3N7eh9dGLohrNyTEahEvMQVV0fHByd4K8zezMLOHTDWnYHJL7LuhKiK8nXcJ8SXHG0H/cmUVmUSUbDhdgEIJJz6/gkzuGMzQxuLU+TpOw2lQtdIvZgG8HjqE3ZVH0PWDKKc5fDCQ5H3OA/zt3s06NQ+o8dI3mTLhrXBdmDoljztjOSCDYx4M5YzsD0CXMl9T8cmx2B6v2q4XSA9llbD5SiM0h2XSk8Rz2tkRt6qVaFNVZLidFSrkSKDjFkMuBD6RiHRAohIhsLgNPYpMOuWg0Z0FssDdPXdmX56/p7xK+ruG+1NglOzKL2XhE/anHHPqUwK2vA7jCMbVYa+zMfncDOzJOTIU8gYNL4NPrIWt74+eX/Qu2ftL4uQM/w6fXs2nHLpadpuSBS9BNRnw8jBiEZOz2h2HuePjkWsjZe3pb67P0CfXe2sfqF+rOHVoOH06HnV+rBb1aKgrg0+vU+C9ugcLUM7tmM9AcwbFoIL3e6wznsazjBwoh5qC8eOLi4s76gjptUaM5e65xFv+qZXjnYCxmA/d8vJkauyTK35OLCz/Bu9gGDOfgcSmNm9MKWbYvl4RQH/rGBJz8Qvkp8OVsqCqG/YvgkucgeTYAy/fl8OQ3m/mp+gWEfxT0vw5X6lp5Pix6GHZ8AcC+o2HMkxcyYfNH0Ocq8OukBHbcwxA3DADz9k/5h+lHPM3/RQhBnGcFPfN/gvDekL4O3hgDod3V/AJImgxj/whmizpWnAmL/waR/aDzeFj5H+jUF/wioeAwLH8Gkm+F9W/AsifBZIGUJbDjS/W5fCPgq9shdRUkjoODi+HATzDjPeg2Gew1sPaVui+BgTfA8N+c9f/hyTivqx1SyrnAXIDk5OSz3perF0U1muYjJsibhyb34B/f78ZiNnBbHwORm/PAAeEUkZJjRkqJqC6DZf8i4Eg2MJ31h05x415dAV/cDAYDzFkBS/4BCx+E8J7YY4bxxA97iCjeivCoVp5szh6I6AV5B+CdyWAtgXF/gv2LGJD9C1m2aihbpL4YasneBXeuhPwUwpf/kZlGwXKTCjp08SiEauCCP0PMUFj5byXaANWlsOpZ2Pw+eDnXBoozoKZcfYmEdgPPALhlAXgFQcYmeOsCWP0i/PIy9LocLn8NNr6j7jBeTgafUCg6AtNeUMJfnAGfXa9E/rKXYeWzkL0D4kaoa1paJkW0OQQ9E6j/lR/jPNYiSCmROoau6QiU5cK82TD5SYjsf+L5vT/A9s/hitfBw7tpcxYcgp//AgljYdgc1+FZIxNYsT+XUF9PhovlruMTArLwLVuL/b9/wmQtBGsRvYExhiTic7Kp/vRNPGa8Cdu/gJ1fwaR/KM/2h98rwb1hHkQNgBnvqlDEl7P4ccRnHMwpY7ppFw5hREgHvy76kIE3Pol5yd/BVq2EOqIX0mCmV9YTBIk8bNFDMfW/BiryoeskeO8SeG0E2KoQ0o6nAF9U+mWiqUAJekAs+IbB1P80/HdIWQpbPgaHc+E0bhgMvwfm3wlZW+GCx5SYA0QPUp7+6ufB6AmTnwJPXxj1W+g5Td0tWEtg6B0wWN2BEBADMz+CN8bCl7eAbyf1uuelTft/OkuaQ9C/A+4VQnwGDAOKpZQnhFuai9qQlQ65aNoF//szGIxKCI9n9fPqFv6XV+CqN9Wx9W9A+gaY/qbyenP3gskLrnxd/XF8cRMEJcCER8HDp26ur26HtPVQlg32KkhdA4NvAZMnoDYsvTd7CEIIyj56ljzpTzClXBqWTRfrQmrs/ph6XIIccD1Z783iGc93iHDkYtwn2fV8Fj0rN2PAAXPHI/06IUoyYfwjkHShur4lAK75EPnWhUQvuYe+kU8ypnA3aV698DELLCk/sm3DJJL3LFDvi+gFQFniFPyWPUGkKCCj60xiht5e95mu+wS2fgpGD9LswcTteAnfGnXXEGtUNWwIbBhectHlAvU4nms/hs0fwPC7644JAYNuUmGgIbdBQHTdueDOygNvjMA4uO5zFXoZeR94tfzGraakLX4KjAdChRAZwF8BM4CU8nVgISpl8SAqbXF2SxkLKtwC6JCLxv3J2q7iqgjod60SsZw9ykvsfgn8+raK1e75Dir/rW79f/wTIFXMNncvRA2E7Z9B53Hq2N7v1dz7FsKtPynvtChNxXrjRkCPSyCiN3x3r/Lw+0yH3P0wfw4i+TYYcAM+R39hsexPXw4ytHgRHqKAVXG/o/P4O3A4JC/VXMl/zHPZTwwbZB9urFjEEdmJXRe+j9z4LtWFR8kwjGHOqD/gWf/zdupD1tinGLj0AV7zeJloDvG1mImnhz+XGt6g+ucblFdcT0yzPOLJc0QQIkrYF3wBMfXnqyfKucu+IQ7wqVFCHkUeFXjhfaahjYAY9WV4PANvhLIcJcxnQtwwV5z/fHBaQZdSXnea8xK4p9ksOg21FTENWtE17kD6r/D97+Ca9yGkS8Nzy55UnquUsPxfKi77+Y1QeASytoHBDFe/q44t/KPy9CJ6qzDBulfB7AM3f6syLpY+ocIyXkEw/S34/Ab46la4cT7sXaiud/mrygaHHVY8A1s+VIK+/nU4ukWJ/P/+jKgqJsVnEF5WB11K12DDwDOH4tn59FISQ31Is4/h96PD+W9KVxZlGAlNTOSdvN5s+CGfUN+r6Z0QwIr9uYzPrjhh0XRezWgqbdfyUO48BA4Wlncn15FIvu0w0X4GJl15K1j8XeOzS6uYa5uNN1ZGlDX+N19YXk2JSYVHvKuVhx4hczkmwujcXHfynn5w4V+bZ64WpO1vATuOWg9dR1w0bsHeBWox7Iub4baf62LdKcvUAt8FjyuBXv6USvGzVcEt36k4sZQq5tqpn/KwI/vDNR8oz/6Lm6DPleoLYeLj8MHlUJKpvNukC+GS5+Hbu2HZE5CxEcJ61H2hGIww4AYl6ukb1Nx9Z0DnCXB0M5i9CPO4Bu9UCalr2GPuw85CEz06+bH3WCmeJjOhF/2BiduOYt+VzcTr/0VSQQXrDxVwxcAo8kqrGfufZezILD5B0H/afQyPqJsRV/2WDUu+Yvn2rjisBlItt2MtsbM94UK86o0/VmxllaMfAHFFJzb2SMkt4+IXV3FBnJEJgKVK5dGH2nM4JEPo3Nz/n20ctxN0HUPXtCkcDnh/moqXXvQk+IQ0PJ/+K/iEqQXCH34PV/wflBxVMe3Q7nWpa/ZqlRnSeTwkjG44x2UvKREfcAMYTRAYD1OeUQty4HzPGBVvH3iTOjbwBsjYoBbshAFG/67hnEPvgE3vwfuXga0SBs9S1x14AwA3AxzKg9SXqOg8mSsN0Tx9VV9W7c+jqLIGs9HA9EExTB+kgiBdwnzpEuYLQGyw2n6/82gxdockq7iSmCBvMosq2ZlZwsMX94CILlQPicCxfb263oh4Xl2WwoJtR8korODOcV3w8TSRU6rq0EQFWDhadGIDjzdWpFBtd/Bzqo0aDyOeTkEPqjlGmn2oys7pQFrhdoKuY+iaNkX2TjiyRj22fQZGM4y6X2VJ2GtUKCN5tvKklz+lxH3//8BmhZkf1i1cTvzLya8RNVA9ahECht/VcMxlL8GRX1yLiYAS/axtyobulzQc7xOqwkDvXaIW9uJHnXjdhDFw8b8ZNuAGhnkqsb6wV8SJ445DCEGf6AB2ZhbzytKDvLB4P7+f1M214/Qi5xxJEWpOs1Ewa2Qiry1P4aGv1AakAG8PbhudyLFiKwFeZjqH+ZJ5nId+rNjK/C2ZGATYpYF8/AmuzIOqMrxsJaQ7QqmyOVwt/ToCbizoWtE1bYDDK9XPG79SWSTHdqhNKeG9VLaJrRJihkCvK1To45eX1GaVaz+GsO7NZ0dwZ/Woj9kC130G+35UqXfHEzccbvpGxYcb+3syGGHYnWdlTt/oAN5dk8qxYis+Hkae/3k/ZqPgySv70NnpyYf7eeJvMZEY5kuYnydDE4LJKrbiZTby8foj3DoqgewSKxH+nkQFWli2L7fBNd5efQiHhHsmdOXlpQfJlQGEVeSqHHAgU4ZQYq3Rgt6WqV0U7Ui3UZo2zOEVENIVul6oHrZq5fV+ey/0v1aNiR2qNthc9ZbK1e57tfLYzwd+nVy7MxslcUyLXLZPdADVdgc5pVXMvWkwhRXVdO/kz4DYuqwTIQS/nZjkKiT27uwhmI0Gvt16lAe/3Ma6QwVkl1YR4W8hKtCL3NIqrDV2hABrtYNP1qcxrV8k1yTH8vLSg+TJAAwVuVCsNq5nylBKrTbC/VrkI7ZJ3E7QpQ65aFqTDW/CxnfhN2vUYuaRX6DfzLrzJg8VynhjLGx8G/yiVCocqDzkIbe1jt3nmT7R6gsrMsDCBT3CG9Rtr8/tY+ruKrw9lBxN6xfJP7/fzQdrU8kutpIUHuoS/SkvrqTGLhmTFEp5tZ27xnUhNtib6EAvCisCEWUHXIJ+1Cno5wNrjR1rjZ1Ab4/zcr2T4XYt6Bx6UVTTmqSuhpxdUJqlYtPVZZA4tuEY/yiVbiiMEDukdexsZeKDvekW4csdYzqfVMxPhsVs5IZhcSzadYzsUtVlqVbQj5VYqai28dmv6YzvHkbPSJXiOLZbKGXmECjPhfwUHMJENkHnrSb6fZ9u4crXfjmhzd/5xg0FXXvomlak4JD6mb27Ln6e0EjYInGMSj9sbAdoB8BgEPz0u3HcOjrxrN5/x5jO+HiYkBIi/D3pGxPAlN6d+Pj24Xx51wjGdgvjj5Pr1iAemdqTaSP6g6MGds2nMnIIDgxNKqGbll/Bn+fvoLLazsbUAkY8tYSs4oYLsJXVdl74eT/FFSfOtzYln593Z3M4r5yMwhNTK88nbivoOoauOe9IqSrvAeTsVjncYT1OTFWsJWG0WhjVnDFBPh7cOioBgAh/C34WM6/fNJjB8UF0Dffjg1uH0juqbh3C32ImOMIZ2irJpKbrxUDTmly8tPQAH69P4+stGby56hBZxVaW7GlYrnfxnmz+u+QAz/60r8Fxh0Pyr4V7XF2dfk09VaXxlsftBF3noWtajfJcVakPlKBn/Aoxya1rUztmzrgu3D8xidFJoU17g2+466mhl8rRX7E/lw2H60S2NiTy3bajXPryajanFfLd1qMA/N/yFBY7hXz1gbwGU9fO8fH6I+w7Vuo6vmD7UXZkFvO3y3rjZzHxa2rrNgNxO0HXIRfNecHm3OhTn9pwi9FT5ZJXFqjSrJoWwdfTxO8mdXMtlp4WH6egR/TFN7wzMUFe/LAji2veWMuSPdn8d/EBkp9YzFM/7uHBL7axI7OYmW+spdru4O7xXcgorMTukAzvHMwvKXnYHXXx8F9TC+gfE4Cfxcx//qeaZVTZ7Px70T56RfozfWA0yfFB2kM/U/SiqOa8sPhv8GySqm7oUP0qXYLeZYISc1ApiZq2gX8kGEzQ81IMBsGKP05gw58n0jvKn998vJkXFu/HYjbyxopDRAd58ebNyQgEY7uFcf+FSUT4ezImKZTrh8VTYrWxI1N1ZCqqqGZfdikX9ozguqFxLN+XS3FFDR+uPUJmUSWPTu2JwSBITgjmYE4ZBeXVLpPSCypYvDsbgJ93Z3PvJ5upqG65hVq3S1t0OHQtF8154OgWqKmEHx9SaXAXPaEEXRgh6SJVh8XTv64Ljqb1sQTA7UsgvCegmmWH+1n4vxsGc+VraxjZO5QXZw5gw+ECuoT5EO5vYeH9own19cTTZGT+3aPwMhuxO6MAi3dn0z8mgI2phUgJQxKD8TQZeH1FCj/tPsabqw4xskuIKyRU20j7+jfX0TPSnwt7RvCXb3eSX17NfRd05Z3VhymvtmMxG3l2RiP17ZsBtxN0HUPXNJnyfFXv27lt/ZQUpalmCLW/V0VHVMEqDx/VpSZmiBL0wFiIHKDGRA9WG4Y0bYeoASccigvx5pdHLsDTpHaMjuhSt4jdtd6uo6jAurJgQxKCeGXZQeZvySTE1wMPo4EBsYF4GA2E+3ny9I97yS+v5l9X9nW9Z0BsIFcNiiGruJLFe7KZvyWTqAALI7uE8PLSg/hbTFw3NI5PN6QxLDGYGcknqdV+DridoLti6PrvSHM63p0CUYNg+hunHpe1TW0EuvEr527PKlVAKygBxvxenf/mblWaNjQJwnuophLHF9HStFlqxbypvHXzEBbtyuLHncdYuT+XEV1CXCUELuodwUfr0ogL9mZ897qFWLPRwHPXKM+7xFrDgm1HmdA9nAAvM3/5dheXD4hiVNdQskuseJhaRsCaJOhCiCnAfwEj8JaU8unjzs8C/kNd67lXpJRvNaOdLnQtF02TKEyFvP1QVXbyMTl7lTgfXKxep61Tgl6cAUgIilcefu3Oz+J01fDXwwfuXqs2EGnaJQHeZmYOiWPmkDhySqwNvhAm9+7ER+vSuHlEPMaTZGf4W8zcMCze9bpW6AHeviW5xdKuT/s1IYQwAq8CFwO9gOuEEL0aGfq5lHKA89EiYg66loumidRu+ik96irW1PD8KnhtGOz5Hg6tUMeyVKU/ClPVz0DnH2RADFz9jipDG9FbHQtOdLVv07Rvwv0tBHibXa9Hdw3l3dlDuGVkwlnN15La1RQPfShwUEp5yGnMZ8DlwO4Ws+oU6FoumiZxeKVawJR2lS8eENPwfK1Xvv51dR5UaAXqBD2ozsOi83h4YIdq9qvp0AghmFAv1NKWaEogJxpIr/c6w3nseK4SQmwXQswTQjQa7RdCzBFCbBRCbMzNzW1syGnRaYuaE8jdp/o91iKlEvSe01RPzvRfT3xPrQefukrVJk8cB2XHoPSYWhA1mFWZ2/oExKgGExpNG6W5IvMLgAQpZT/gZ+D9xgZJKedKKZOllMlhYWFndSG9sUjTgMoimDseXk5WHXgcDtU8uSxbxcOjBqrOPaDOpW+AigLI2qoaM4Py5GsbE2dtVz09A+NUPXCNxo1oiruRCdT3uGOoW/wEQEqZX+/lW8C/z920xtG1XDQN2PEl1FSofpsL7lddg4rSlIfdeYJaGF3/hspc2fguLPoTxI0E6YBBN4G1SL0/fqSa79g25aHXD7doNG5CUzz0X4EkIUSiEMIDuBb4rv4AIUT9e9PLgD3NZ2JDdB56B6eyUGWj1LLlQ4joC3NWwKUvqSqInn4we6HKGU8Yq/p1rvg3rHoWjB6Q9otKO4wZopouX/+l6jQf3AUytzg9dC3oGvfjtB66lNImhLgX+B8qbfEdKeUuIcQ/gI1Syu+A3wohLgNsQAEwq6UM1iGXDs6q52Dta/DHgyqNMGsbXPwftSFo8C2qG5DJUhcuSZoEvacrMQe4+Tv4+S8qHn58lkriGBW2Ae2ha9ySJq3wSCkXAguPO/aXes8fAR5pXtMaRy+KtjPyU8Ba3HjPS4D9P0HcsLqWbWnrVeZK6mpIX69CK32vrhtf23S5FiHgspfVLs+QLtB5HNy+WKUgHs+UZ8A71LkzVNdo0bgfbrffsi6G3sqGaJqHHx+CT64Bh12J+/6f6uJqBYfgkxmw9lX12lalFjNB9fLct1AJtHfwqa/h6Qt3LIPpzu0RRnPjC55mC0x8HB7LhoRRzfP5NJrziNsJutQ7RdsX2btUnfGMX9X2+k9mwMczVCZK7Yaf+ht/7NVg9laLoQWHoPvUpl3HYGh6vQj9u6VxU9xO0HXIpR1RUaB6cwKsfgHS10GXCyBlKax5UXnhAJkb1Rb+2vTDwbNVmAaaLugaTQfA/QTdoRdF2w25qlEAHn6qHK3BBFe+Ad2mwNZP1eafgDhw2FRmS/oGVRGx/0z1vuhkVQNbo9EA7ijoqz/61QAAC9tJREFUupZL+yHHWT1i6B3qZ/eLVRuxQTdBeQ5U5MPo+1Wq4f5FahE0ZohKU4weDINntZrpGk1bxO0EXddycTOqSlU4paaRbug5e8AzAIb/BkKSYPg96njXSXU1U5Imq4yTX99U4Zmel6pY+B1LlfBrNBoXbleYwhVD14ruHvz6tmrnJh2QfBts/Vh51h4+StDDeyqv/L6Nde8xmlQd8pRlanPQoJvUbs5Jf4fEsa31STSaNo8bCrr20Ns85fmwYS6MvE/t5ARY819IXQMpS1Ra4oh7VIZL7ysbn2PYneoB0P9a9dBoNKfE7UIudl3Lpe2x+UO14aeWnfNgxdPw/jTIPwjDfqOyUlKWqBDLlg+hJFPVUQlvrLS+RqM5G9zOQ6+NoRu1oJ8btmpY/pSKX/ueQ23n6nL4/ndqI87N36pj6RsAoRote/ipzTpmC9hrILQbLPgtfHqtympJHNMsH0ej0bihoDsc6qfOQz9HjqyB1c+rPpmjftvI+bVqe/3YB9VGGylVgaukSQ236aetA0eN+mmrUvVRMjaoxUu/SNXZx8MHLvybGl9VCosegWM7YPJTrg7tGo3m3HE/Qddb/5uH2i49Gb8qb/3nx2HIHRDaFew2+O5eFS6JSYYuE+DAT7D8X5C3T7Vjq6V284/NquYKSVLla4feCSPvPfG6nn5wwWOqXvnw37T859RoOhBuF0PXO0XPkIoC+O4+KM9reLy+oB9arlqxLXpYHdv+mRJzkxcs/f/2zj3GivqK458jjw3yEASkFHnstkizIkVcECKvpD5YVMCKQIv12ZpaSWq0oVgSS7TGotGqiS31QYtWxVpfm1arqATaBpUFFwVEWBBxccEWLWsj8pDTP87vyuyyd/cu7J2593I+yeTO/Oa3M98987vn/ubMmd/vVrsteu1W2/f+cuut/+MuqH7VtnsNtsGutiw7dNy+TQxuNeonlrHi19BxWpW866F/lYeedz9FCVG5EFY/Ym9YjpttZarmeNt2sNzuNx+w8uolUPU4LL0deg+Fsitt0ogHx1uIpGS8Of91z8Crt9iYKge+gLGzLdTy/nL4cq+9CNT7243rcRwna+SdW/QeejMsvxP+cD4sngn//fBQ2uDqRw89gNhVbRNFDP2+bVcvgYHnQseT4LlrLc5dPh+GzoTBF9v44kOmwwX3WP0XZtuwte07WX55yTjLD69ZCW/9Cb425PCxxh3HyTp510Mv/XoXfnlhKT07ucM4jJ3r4bXbLJPko7dg4QSoq4FTymHjixYm2b4Kju9u9cuutB75gT1w2iX2ws+mJTB+DnQOb2pG4+UA3QbAp1uhdAqMmmV3ACcPt2N+VGWZLGVXxvhPO46TIiOHLiITgHuxGYseUtVfN9hfBDwCnAHsAqar6tbWlWoU9+hIcY/ibBw6N9j7P0vrO3k4jLjGylY+BNtW2EQNRZ2tTBXWPAEb/mY95049Yelttv+qv1v446nLLe/7ogVw31BY+ivrWR/cb+UnnWoZK9tet+yVDt3gW+c3ra94nDn0YZdB3+G2APQcBJc9lzWzOI7TPM06dBFpA9wPnAPUACtFpEJV10eqXQ18qqrfFJEZwHxgejYEt5gty6xnOmS6hRiOJlRz8CCsXgTrn4NxP7eJhT/bYVOaFXWxfOvUzDqff2Jx5i/3wZgbbaLiPZ/CObfYCIEfrIBl86F0Egy7wh4KqFrMeu3Ttqz4LQiWNQK2v/9Z9vr83jobDxxs/bRpsOGvMP4XNuHDqVNgzz0WFunQFcrvsAkkRl5rMfX2He2cZ10PgzaaM8+EET+yY5aMP3I7Oo6TFST1kDFtBZFRwDxVPS9s3wSgqrdH6rwU6qwQkbbADqCnNnHwsrIyraysTLc7PdWvwEtzM6urB23W93bH21ggXftDuw4tP2eKfZ/D7m2HjtfjFKirNad9cL858069rO5ntdbbluNsnxxnveM27aBLH0v/Sx3nhH7Q/ngLV3yy2dL6uhXDumftWKWT7c3KV+bZdp8zbPCqgWfbMStCemDfkXDpXw714h3HKThEZJWqljW2L5OQSx/gw8h2DXBmujphUundQHegXq6ciFwDXAPQr1+/jMQfRlEXu73PlMFTLR/67T/DlqVHds4o42bb+CP/utecct8RMPoGe7X9jQWW9QGWJTLqOsv4ePP3MPRS6yn/8zfWoy6dZL3j9c9bjjfht2/INBh9o/Weo3NlqprD7zbA4t3RO429dfZDlerpO45zTJJJD30qMEFVfxi2fwCcqaqzInXWhjo1YXtzqPOfxo4JR9FDdxzHOYZpqoeeSXduO9A3sn1yKGu0Tgi5nIA9HHUcx3FiIhOHvhIYKCLFItIemAFUNKhTAVwe1qcCrzUVP3ccx3Fan2Zj6CEmPgt4CUtbXKiq60TkFqBSVSuAh4FHRaQa+ARz+o7jOE6MZJSHrqovAC80KLs5sv4FcEnrSnMcx3FagqdEOI7jFAju0B3HcQoEd+iO4zgFgjt0x3GcAqHZF4uydmKRfwMfHOGf96DBW6g5Qq7qgtzV5rpahutqGYWoq7+q9mxsR2IO/WgQkcp0b0olSa7qgtzV5rpahutqGceaLg+5OI7jFAju0B3HcQqEfHXoDyQtIA25qgtyV5vrahmuq2UcU7ryMobuOI7jHE6+9tAdx3GcBrhDdxzHKRDyzqGLyAQReU9EqkVkToI6+orIUhFZLyLrROSnoXyeiGwXkaqwTExA21YReSecvzKUnSgiS0RkU/jMcBLRVtM0KGKTKhGpE5Hrk7CXiCwUkY/DxCypskbtI8Z9ob29LSLDYtZ1p4hsCOd+VkS6hvIBIrInYrcFMetKe91E5KZgr/dE5LyYdT0Z0bRVRKpCeZz2Sucbst/GVDVvFmz43s1ACdAeWAOUJqSlNzAsrHcGNgKlwDzgZwnbaSvQo0HZHcCcsD4HmJ/wddwB9E/CXsBYYBiwtjn7ABOBF7HpukcCb8Ss61ygbVifH9E1IFovAXs1et3Cd2ANUAQUh+9rm7h0Ndh/F3BzAvZK5xuy3sbyrYc+AqhW1S2qug9YDExOQoiq1qrq6rD+GfAuNrdqrjIZWBTWFwFTEtTyHWCzqh7pm8JHhaoux8btj5LOPpOBR9R4HegqIr3j0qWqL6vqgbD5OjZjWKyksVc6JgOLVXWvqr4PVGPf21h1iYgA04AnsnHupmjCN2S9jeWbQ29swurEnaiIDABOB94IRbPCrdPCuEMbAQVeFpFVYhNzA/RS1dqwvgPolYCuFDOo/0VL2l6Q3j651OauwnpyKYpF5C0RWSYiYxLQ09h1yxV7jQF2quqmSFns9mrgG7LexvLNoeccItIJeBq4XlXrgN8B3wCGArXYbV/cjFbVYUA5cJ2IjI3uVLvPSyRfVWwaw0nAU6EoF+xVjyTtkw4RmQscAB4LRbVAP1U9HbgBeFxEusQoKeeuWwO+R/1OQ+z2asQ3fEW22li+OfRMJqyODRFph12wx1T1GQBV3amqX6rqQeBBsnS72RSquj18fgw8GzTsTN3Ghc+P49YVKAdWq+rOoDFxewXS2SfxNiciVwAXADODIyCENHaF9VVYrPqUuDQ1cd1ywV5tge8CT6bK4rZXY76BGNpYvjn0TCasjoUQo3sYeFdV746UR2NfFwFrG/5tlnV1FJHOqXXsodpa6k/kfTnwfJy6ItTrOSVtrwjp7FMBXBYyEUYCuyO3zVlHRCYAs4FJqvp5pLyniLQJ6yXAQGBLjLrSXbcKYIaIFIlIcdD1Zly6AmcDG1S1JlUQp73S+QbiaGNxPPVtzQV7IrwR+4Wdm6CO0dgt09tAVVgmAo8C74TyCqB3zLpKsCyDNcC6lI2A7sCrwCbgFeDEBGzWEdgFnBApi91e2A9KLbAfi1denc4+WObB/aG9vQOUxayrGouvptrYglD34nB9q4DVwIUx60p73YC5wV7vAeVx6grlfwR+3KBunPZK5xuy3sb81X/HcZwCId9CLo7jOE4a3KE7juMUCO7QHcdxCgR36I7jOAWCO3THcZwCwR264zhOgeAO3XEcp0D4P7QYv/jOBbGYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3OkYcv8PzfR"
      },
      "source": [
        "Test the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Js4WPC6Px6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7527d7-20d7-4862-9105-fd9284a3cd7b"
      },
      "source": [
        "TEST_ITER_NUM = 10000\n",
        "\n",
        "n_yes = 0\n",
        "n_no  = 0\n",
        "\n",
        "for i in range(TEST_ITER_NUM + 1):\n",
        "    # a + b = c\n",
        "    # generate test data\n",
        "\n",
        "    a_dec = np.random.randint(largest / 2)\n",
        "    b_dec = np.random.randint(largest / 2)\n",
        "    c_dec = a_dec + b_dec\n",
        "    \n",
        "    a_bin = binary[a_dec]\n",
        "    b_bin = binary[b_dec]\n",
        "    c_bin = binary[c_dec]\n",
        "    \n",
        "    pred = np.zeros_like(c_bin)\n",
        "    \n",
        "    overall_err = 0 # total error in the whole calculation process.\n",
        "    \n",
        "    output_deltas = list()\n",
        "    hidden_values = list()\n",
        "    hidden_values.append(np.zeros(HIDDEN_DIM))\n",
        "    \n",
        "    future_delta = np.zeros(HIDDEN_DIM)\n",
        "    \n",
        "\n",
        "    # forward propagation\n",
        "    for pos in range(BIN_DIM)[::-1]:\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]]) # shape=(1, 2)\n",
        "        Y = np.array([[c_bin[pos]]]) # shape=(1, 1)\n",
        "        \n",
        "        hidden = sigmoid(np.dot(X, w0) + np.dot(hidden_values[-1], wh))\n",
        "        output = sigmoid(np.dot(hidden, w1))\n",
        "        \n",
        "        pred[pos] = np.round(output[0][0])\n",
        "\n",
        "        # squared mean error\n",
        "        output_err = Y - output\n",
        "        output_deltas.append(output_err * deriv_sigmoid(output))\n",
        "        hidden_values.append(hidden)\n",
        "        \n",
        "        overall_err += np.abs(output_err[0])        \n",
        "\n",
        "\n",
        "\n",
        "    # accuracy\n",
        "    if (bin2dec(pred) == c_dec): \n",
        "      n_yes += 1\n",
        "    else:\n",
        "      n_no  += 1\n",
        "    \n",
        "    if i<30:\n",
        "      print('Iter', i)\n",
        "      print(\"Error :\", overall_err)\n",
        "      print(\"Pred :\", pred)\n",
        "      print(\"True :\", c_bin)\n",
        "      print(a_dec, \"+\", b_dec, \"=\", bin2dec(pred))\n",
        "      print('----------')\n",
        "\n",
        "# calculate accuracy\n",
        "acc = float(n_yes)/float(n_yes+n_no)\n",
        "\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"RNN accuracy = \",acc)\n",
        "print(\" \")\n",
        "print(\" \")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0\n",
            "Error : [0.40032932]\n",
            "Pred : [1 0 1 1 1 1 1 1]\n",
            "True : [1 0 1 1 1 1 1 1]\n",
            "121 + 70 = 191\n",
            "----------\n",
            "Iter 1\n",
            "Error : [0.77139251]\n",
            "Pred : [0 1 0 0 1 0 1 1]\n",
            "True : [0 1 0 0 1 0 1 1]\n",
            "56 + 19 = 75\n",
            "----------\n",
            "Iter 2\n",
            "Error : [0.74520805]\n",
            "Pred : [0 1 1 0 1 1 0 0]\n",
            "True : [0 1 1 0 1 1 0 0]\n",
            "61 + 47 = 108\n",
            "----------\n",
            "Iter 3\n",
            "Error : [0.36199184]\n",
            "Pred : [0 1 1 0 1 1 1 0]\n",
            "True : [0 1 1 0 1 1 1 0]\n",
            "89 + 21 = 110\n",
            "----------\n",
            "Iter 4\n",
            "Error : [0.60429172]\n",
            "Pred : [1 1 0 0 0 1 1 1]\n",
            "True : [1 1 0 0 0 1 1 1]\n",
            "109 + 90 = 199\n",
            "----------\n",
            "Iter 5\n",
            "Error : [1.27517745]\n",
            "Pred : [0 0 1 0 1 1 1 1]\n",
            "True : [0 0 1 0 1 0 1 1]\n",
            "4 + 39 = 47\n",
            "----------\n",
            "Iter 6\n",
            "Error : [0.51147943]\n",
            "Pred : [1 0 1 0 0 1 1 1]\n",
            "True : [1 0 1 0 0 1 1 1]\n",
            "71 + 96 = 167\n",
            "----------\n",
            "Iter 7\n",
            "Error : [0.50790345]\n",
            "Pred : [0 1 1 0 0 1 1 0]\n",
            "True : [0 1 1 0 0 1 1 0]\n",
            "11 + 91 = 102\n",
            "----------\n",
            "Iter 8\n",
            "Error : [1.06246204]\n",
            "Pred : [0 1 1 1 1 0 0 1]\n",
            "True : [0 1 1 1 1 0 0 1]\n",
            "74 + 47 = 121\n",
            "----------\n",
            "Iter 9\n",
            "Error : [0.51531325]\n",
            "Pred : [0 1 1 0 1 1 0 0]\n",
            "True : [0 1 1 0 1 1 0 0]\n",
            "7 + 101 = 108\n",
            "----------\n",
            "Iter 10\n",
            "Error : [0.47521683]\n",
            "Pred : [0 1 0 0 0 1 1 1]\n",
            "True : [0 1 0 0 0 1 1 1]\n",
            "7 + 64 = 71\n",
            "----------\n",
            "Iter 11\n",
            "Error : [0.37063131]\n",
            "Pred : [1 0 1 0 1 0 1 0]\n",
            "True : [1 0 1 0 1 0 1 0]\n",
            "65 + 105 = 170\n",
            "----------\n",
            "Iter 12\n",
            "Error : [0.56726497]\n",
            "Pred : [1 1 0 0 0 0 1 1]\n",
            "True : [1 1 0 0 0 0 1 1]\n",
            "105 + 90 = 195\n",
            "----------\n",
            "Iter 13\n",
            "Error : [0.65242861]\n",
            "Pred : [0 1 0 0 0 0 0 1]\n",
            "True : [0 1 0 0 0 0 0 1]\n",
            "3 + 62 = 65\n",
            "----------\n",
            "Iter 14\n",
            "Error : [0.63335023]\n",
            "Pred : [1 1 0 0 1 1 0 0]\n",
            "True : [1 1 0 0 1 1 0 0]\n",
            "82 + 122 = 204\n",
            "----------\n",
            "Iter 15\n",
            "Error : [0.43069938]\n",
            "Pred : [0 1 0 1 1 1 0 0]\n",
            "True : [0 1 0 1 1 1 0 0]\n",
            "90 + 2 = 92\n",
            "----------\n",
            "Iter 16\n",
            "Error : [0.61026617]\n",
            "Pred : [1 0 1 1 0 1 1 0]\n",
            "True : [1 0 1 1 0 1 1 0]\n",
            "62 + 120 = 182\n",
            "----------\n",
            "Iter 17\n",
            "Error : [0.4589962]\n",
            "Pred : [0 1 1 0 1 1 0 1]\n",
            "True : [0 1 1 0 1 1 0 1]\n",
            "1 + 108 = 109\n",
            "----------\n",
            "Iter 18\n",
            "Error : [0.7961386]\n",
            "Pred : [1 1 1 0 1 1 0 1]\n",
            "True : [1 1 1 0 1 1 0 1]\n",
            "111 + 126 = 237\n",
            "----------\n",
            "Iter 19\n",
            "Error : [0.41143899]\n",
            "Pred : [0 0 1 1 0 1 0 0]\n",
            "True : [0 0 1 1 0 1 0 0]\n",
            "17 + 35 = 52\n",
            "----------\n",
            "Iter 20\n",
            "Error : [0.37570143]\n",
            "Pred : [1 0 0 1 0 0 0 0]\n",
            "True : [1 0 0 1 0 0 0 0]\n",
            "40 + 104 = 144\n",
            "----------\n",
            "Iter 21\n",
            "Error : [0.6400417]\n",
            "Pred : [0 1 1 1 0 1 0 1]\n",
            "True : [0 1 1 1 0 1 0 1]\n",
            "98 + 19 = 117\n",
            "----------\n",
            "Iter 22\n",
            "Error : [0.97954314]\n",
            "Pred : [1 0 1 0 1 0 1 1]\n",
            "True : [1 0 1 0 1 0 1 1]\n",
            "48 + 123 = 171\n",
            "----------\n",
            "Iter 23\n",
            "Error : [0.48016762]\n",
            "Pred : [0 1 1 1 1 1 1 0]\n",
            "True : [0 1 1 1 1 1 1 0]\n",
            "76 + 50 = 126\n",
            "----------\n",
            "Iter 24\n",
            "Error : [0.39213007]\n",
            "Pred : [0 1 0 1 1 0 1 0]\n",
            "True : [0 1 0 1 1 0 1 0]\n",
            "34 + 56 = 90\n",
            "----------\n",
            "Iter 25\n",
            "Error : [0.61303458]\n",
            "Pred : [1 0 0 1 0 0 1 0]\n",
            "True : [1 0 0 1 0 0 1 0]\n",
            "99 + 47 = 146\n",
            "----------\n",
            "Iter 26\n",
            "Error : [0.49673995]\n",
            "Pred : [1 0 0 0 0 0 1 0]\n",
            "True : [1 0 0 0 0 0 1 0]\n",
            "112 + 18 = 130\n",
            "----------\n",
            "Iter 27\n",
            "Error : [0.51302714]\n",
            "Pred : [0 0 0 0 1 1 0 0]\n",
            "True : [0 0 0 0 1 1 0 0]\n",
            "5 + 7 = 12\n",
            "----------\n",
            "Iter 28\n",
            "Error : [0.6424536]\n",
            "Pred : [0 1 0 1 0 0 0 1]\n",
            "True : [0 1 0 1 0 0 0 1]\n",
            "14 + 67 = 81\n",
            "----------\n",
            "Iter 29\n",
            "Error : [0.60580997]\n",
            "Pred : [0 1 0 1 0 0 0 1]\n",
            "True : [0 1 0 1 0 0 0 1]\n",
            "55 + 26 = 81\n",
            "----------\n",
            " \n",
            " \n",
            " \n",
            "---------------------------------------------------\n",
            " \n",
            "RNN accuracy =  0.9676032396760323\n",
            " \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVfu6nca1fG0"
      },
      "source": [
        "# **Now training using keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHgY2YOR1iv_",
        "outputId": "66e64b77-728c-4654-a71b-bd02a816d69d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, TimeDistributed, Dense,SimpleRNN\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training dataset generation                            \n",
        "int2binary = {}                                    #Use to convert the input integer to a computer-operable binary number\n",
        "binary_dim = 8                                     #defined the length of the binary number = 8\n",
        "\n",
        "largest_number = pow(2,binary_dim)                         #  The maximum number that can be taken is =256 \n",
        "binary = np.unpackbits(\n",
        "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)            \n",
        "for i in range(largest_number):                                # one-one correspondence between binary numbers and decimal numbers\n",
        "    int2binary[i] = binary[i]\n",
        "\n",
        "x_train = []  \n",
        "y_train = []  \n",
        "for j in range(1000):          #Model iteration times, you can change it yourself\n",
        "    # generate a simple addition problem (a + b = c)\n",
        "    a_int = np.random.randint(largest_number/2) # int version #constrained initialization input addenda a value does not exceed 128\n",
        "    a = list(int2binary[a_int]) # binary encoding # Convert the addend a to the corresponding binary number\n",
        "    a.reverse()\n",
        "\n",
        "    b_int = np.random.randint(largest_number/2) # int version\n",
        "    b = list(int2binary[b_int]) # binary encoding\n",
        "    b.reverse()\n",
        "\n",
        "    c_int = a_int + b_int    # \n",
        "    c = list(int2binary[c_int])\n",
        "    c.reverse()  \n",
        "\n",
        "\n",
        "\n",
        "    tempx = np.hstack((np.array([a]).T,np.array([b]).T))\n",
        "\n",
        "    tempx = np.array(tempx.reshape(8,2))\n",
        "    tempy = np.array([c]).reshape((8,1))\n",
        "\n",
        "    x_train.append(tempx)\n",
        "    y_train.append(tempy)\n",
        "     \n",
        "    \n",
        "    \n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=0)\n",
        "print(x_train.shape)  \n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Example training data:\")\n",
        "print(np.flipud(x_train[0,:,0]),\" + \",np.flipud(x_train[0,:,1]),\" = \",np.flipud(y_train[0,:,0]))\n",
        "print(np.flipud(x_train[1,:,0]),\" + \",np.flipud(x_train[1,:,1]),\" = \",np.flipud(y_train[1,:,0]))\n",
        "print(np.flipud(x_train[2,:,0]),\" + \",np.flipud(x_train[2,:,1]),\" = \",np.flipud(y_train[2,:,0]))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700, 8, 2)\n",
            "(700, 8, 1)\n",
            "Example training data:\n",
            "[0 1 0 0 0 1 0 0]  +  [0 0 0 0 1 1 0 1]  =  [0 1 0 1 0 0 0 1]\n",
            "[0 0 1 1 0 0 1 1]  +  [0 1 1 0 0 1 0 0]  =  [1 0 0 1 0 1 1 1]\n",
            "[0 0 0 1 0 1 1 1]  +  [0 1 0 1 0 1 1 1]  =  [0 1 1 0 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZDBZvxmpE5"
      },
      "source": [
        "# **Define model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B4EoKUump-6",
        "outputId": "a9fafc06-6288-4a1f-f656-5e7cd69bafb4"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128, input_shape=(8, 2),return_sequences=True,activation=\"sigmoid\"))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary() \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 8, 128)            16768     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 8, 1)              129       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 1)              0         \n",
            "=================================================================\n",
            "Total params: 16,897\n",
            "Trainable params: 16,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3qinYUxlDH1"
      },
      "source": [
        "# **Train the RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCCuEQgLYEdv",
        "outputId": "5499a395-62e2-4359-c613-a2a4c33e58da"
      },
      "source": [
        "history = model.fit(x_train, y_train, 32, 300,validation_data=(x_val, y_val)) \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 2s 28ms/step - loss: 0.7144 - accuracy: 0.5053 - val_loss: 0.6953 - val_accuracy: 0.5017\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5094 - val_loss: 0.6939 - val_accuracy: 0.4967\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5137 - val_loss: 0.6932 - val_accuracy: 0.4967\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6921 - val_accuracy: 0.5458\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6912 - val_accuracy: 0.5517\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5476 - val_loss: 0.6938 - val_accuracy: 0.4967\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6922 - val_accuracy: 0.5017\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5133 - val_loss: 0.6901 - val_accuracy: 0.5433\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5444 - val_loss: 0.6898 - val_accuracy: 0.5421\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.5421 - val_loss: 0.6944 - val_accuracy: 0.5017\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5251 - val_loss: 0.6898 - val_accuracy: 0.5271\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5190 - val_loss: 0.6903 - val_accuracy: 0.5333\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.5404 - val_loss: 0.6896 - val_accuracy: 0.5271\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5326 - val_loss: 0.6881 - val_accuracy: 0.5667\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.5574 - val_loss: 0.6880 - val_accuracy: 0.5442\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.5282 - val_loss: 0.6896 - val_accuracy: 0.5354\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5325 - val_loss: 0.6876 - val_accuracy: 0.5412\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5489 - val_loss: 0.6879 - val_accuracy: 0.5375\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5378 - val_loss: 0.6879 - val_accuracy: 0.5325\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.5605 - val_loss: 0.6882 - val_accuracy: 0.5417\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.5363 - val_loss: 0.6869 - val_accuracy: 0.5471\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.5586 - val_loss: 0.6867 - val_accuracy: 0.5371\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5515 - val_loss: 0.6879 - val_accuracy: 0.5454\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5485 - val_loss: 0.6863 - val_accuracy: 0.5475\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5600 - val_loss: 0.6868 - val_accuracy: 0.5638\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.5484 - val_loss: 0.6889 - val_accuracy: 0.5358\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6865 - accuracy: 0.5554 - val_loss: 0.6863 - val_accuracy: 0.5471\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.5583 - val_loss: 0.6898 - val_accuracy: 0.5417\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.5560 - val_loss: 0.6871 - val_accuracy: 0.5337\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.5431 - val_loss: 0.6870 - val_accuracy: 0.5358\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5417 - val_loss: 0.6874 - val_accuracy: 0.5467\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5583 - val_loss: 0.6857 - val_accuracy: 0.5546\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5457 - val_loss: 0.6864 - val_accuracy: 0.5437\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5482 - val_loss: 0.6879 - val_accuracy: 0.5433\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.5553 - val_loss: 0.6862 - val_accuracy: 0.5725\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5620 - val_loss: 0.6890 - val_accuracy: 0.5533\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5638 - val_loss: 0.6855 - val_accuracy: 0.5612\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.5619 - val_loss: 0.6863 - val_accuracy: 0.5675\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6855 - accuracy: 0.5580 - val_loss: 0.6863 - val_accuracy: 0.5671\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5597 - val_loss: 0.6854 - val_accuracy: 0.5654\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6845 - accuracy: 0.5639 - val_loss: 0.6877 - val_accuracy: 0.5542\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.5724 - val_loss: 0.6852 - val_accuracy: 0.5533\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.5607 - val_loss: 0.6852 - val_accuracy: 0.5633\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5767 - val_loss: 0.6856 - val_accuracy: 0.5596\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.5790 - val_loss: 0.6864 - val_accuracy: 0.5654\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.5665 - val_loss: 0.6851 - val_accuracy: 0.5721\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5594 - val_loss: 0.6883 - val_accuracy: 0.5450\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.5551 - val_loss: 0.6880 - val_accuracy: 0.5575\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.5548 - val_loss: 0.6856 - val_accuracy: 0.5437\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.5596 - val_loss: 0.6846 - val_accuracy: 0.5733\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5719 - val_loss: 0.6850 - val_accuracy: 0.5621\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6826 - accuracy: 0.5789 - val_loss: 0.6848 - val_accuracy: 0.5654\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.5712 - val_loss: 0.6854 - val_accuracy: 0.5608\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5520 - val_loss: 0.6843 - val_accuracy: 0.5683\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.5575 - val_loss: 0.6849 - val_accuracy: 0.5746\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5623 - val_loss: 0.6851 - val_accuracy: 0.5654\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5691 - val_loss: 0.6862 - val_accuracy: 0.5558\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.5627 - val_loss: 0.6859 - val_accuracy: 0.5600\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.5462 - val_loss: 0.6853 - val_accuracy: 0.5408\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.5547 - val_loss: 0.6842 - val_accuracy: 0.5658\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5722 - val_loss: 0.6839 - val_accuracy: 0.5658\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.5714 - val_loss: 0.6840 - val_accuracy: 0.5750\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5724 - val_loss: 0.6841 - val_accuracy: 0.5733\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5678 - val_loss: 0.6840 - val_accuracy: 0.5446\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.5719 - val_loss: 0.6856 - val_accuracy: 0.5312\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5647 - val_loss: 0.6838 - val_accuracy: 0.5742\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6772 - accuracy: 0.5913 - val_loss: 0.6834 - val_accuracy: 0.5587\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5619 - val_loss: 0.6836 - val_accuracy: 0.5754\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.5630 - val_loss: 0.6843 - val_accuracy: 0.5612\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.5603 - val_loss: 0.6873 - val_accuracy: 0.5467\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5557 - val_loss: 0.6834 - val_accuracy: 0.5738\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5892 - val_loss: 0.6828 - val_accuracy: 0.5650\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5790 - val_loss: 0.6830 - val_accuracy: 0.5579\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.5742 - val_loss: 0.6827 - val_accuracy: 0.5708\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5785 - val_loss: 0.6826 - val_accuracy: 0.5667\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5671 - val_loss: 0.6823 - val_accuracy: 0.5750\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5800 - val_loss: 0.6855 - val_accuracy: 0.5267\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5742 - val_loss: 0.6820 - val_accuracy: 0.5975\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.6145 - val_loss: 0.6820 - val_accuracy: 0.5942\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6830 - accuracy: 0.5786 - val_loss: 0.6838 - val_accuracy: 0.5400\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5614 - val_loss: 0.6820 - val_accuracy: 0.5946\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.5910 - val_loss: 0.6814 - val_accuracy: 0.5962\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5935 - val_loss: 0.6814 - val_accuracy: 0.5612\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.5832 - val_loss: 0.6837 - val_accuracy: 0.5617\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6824 - accuracy: 0.5827 - val_loss: 0.6806 - val_accuracy: 0.6104\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5896 - val_loss: 0.6814 - val_accuracy: 0.5879\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.5789 - val_loss: 0.6804 - val_accuracy: 0.5800\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5774 - val_loss: 0.6801 - val_accuracy: 0.5829\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.5998 - val_loss: 0.6810 - val_accuracy: 0.5675\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5851 - val_loss: 0.6822 - val_accuracy: 0.5587\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5909 - val_loss: 0.6790 - val_accuracy: 0.6083\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5969 - val_loss: 0.6790 - val_accuracy: 0.6062\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.5920 - val_loss: 0.6808 - val_accuracy: 0.5346\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6781 - val_accuracy: 0.5896\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.5782 - val_loss: 0.6776 - val_accuracy: 0.6117\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.6123 - val_loss: 0.6771 - val_accuracy: 0.6137\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6744 - accuracy: 0.6198 - val_loss: 0.6766 - val_accuracy: 0.6279\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.6112 - val_loss: 0.6762 - val_accuracy: 0.6237\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.5972 - val_loss: 0.6779 - val_accuracy: 0.5350\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.5535 - val_loss: 0.6750 - val_accuracy: 0.6167\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6759 - accuracy: 0.6066 - val_loss: 0.6744 - val_accuracy: 0.5883\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6729 - accuracy: 0.6084 - val_loss: 0.6748 - val_accuracy: 0.6112\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6754 - accuracy: 0.6042 - val_loss: 0.6756 - val_accuracy: 0.5833\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.5976 - val_loss: 0.6729 - val_accuracy: 0.6329\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6731 - accuracy: 0.6159 - val_loss: 0.6710 - val_accuracy: 0.6254\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.5898 - val_loss: 0.6712 - val_accuracy: 0.6121\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.6175 - val_loss: 0.6689 - val_accuracy: 0.6404\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6671 - accuracy: 0.6285 - val_loss: 0.6684 - val_accuracy: 0.6342\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6700 - accuracy: 0.6314 - val_loss: 0.6672 - val_accuracy: 0.5479\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6695 - accuracy: 0.6054 - val_loss: 0.6653 - val_accuracy: 0.5863\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6680 - accuracy: 0.5887 - val_loss: 0.6637 - val_accuracy: 0.5958\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6632 - accuracy: 0.6159 - val_loss: 0.6629 - val_accuracy: 0.5462\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6622 - accuracy: 0.5835 - val_loss: 0.6606 - val_accuracy: 0.6221\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.6313 - val_loss: 0.6588 - val_accuracy: 0.6237\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.5849 - val_loss: 0.6584 - val_accuracy: 0.6375\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6589 - accuracy: 0.6035 - val_loss: 0.6549 - val_accuracy: 0.6171\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.6104 - val_loss: 0.6531 - val_accuracy: 0.5608\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.6290 - val_loss: 0.6518 - val_accuracy: 0.5633\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.5879 - val_loss: 0.6487 - val_accuracy: 0.5904\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.6217 - val_loss: 0.6466 - val_accuracy: 0.6383\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.6486 - val_loss: 0.6447 - val_accuracy: 0.5700\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6423 - accuracy: 0.6125 - val_loss: 0.6394 - val_accuracy: 0.5987\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6213 - val_loss: 0.6379 - val_accuracy: 0.6458\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.6277 - val_loss: 0.6327 - val_accuracy: 0.5958\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.5947 - val_loss: 0.6292 - val_accuracy: 0.6079\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6316 - accuracy: 0.6449 - val_loss: 0.6258 - val_accuracy: 0.6525\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6302 - accuracy: 0.6459 - val_loss: 0.6232 - val_accuracy: 0.6050\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6287 - val_loss: 0.6179 - val_accuracy: 0.6575\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.6619 - val_loss: 0.6131 - val_accuracy: 0.6592\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.6636 - val_loss: 0.6095 - val_accuracy: 0.6308\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.6616 - val_loss: 0.6036 - val_accuracy: 0.6879\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6772 - val_loss: 0.5987 - val_accuracy: 0.6933\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.7045 - val_loss: 0.5927 - val_accuracy: 0.6896\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5904 - accuracy: 0.7095 - val_loss: 0.5911 - val_accuracy: 0.7225\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.7276 - val_loss: 0.5814 - val_accuracy: 0.7071\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.7174 - val_loss: 0.5763 - val_accuracy: 0.7146\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.7155 - val_loss: 0.5697 - val_accuracy: 0.7083\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.7163 - val_loss: 0.5637 - val_accuracy: 0.7071\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5634 - accuracy: 0.7291 - val_loss: 0.5559 - val_accuracy: 0.7204\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7245 - val_loss: 0.5487 - val_accuracy: 0.7779\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.7545 - val_loss: 0.5476 - val_accuracy: 0.7150\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7311 - val_loss: 0.5356 - val_accuracy: 0.7142\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7467 - val_loss: 0.5258 - val_accuracy: 0.7254\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7377 - val_loss: 0.5197 - val_accuracy: 0.7138\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7610 - val_loss: 0.5101 - val_accuracy: 0.7346\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.8006 - val_loss: 0.4995 - val_accuracy: 0.7638\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.8052 - val_loss: 0.4926 - val_accuracy: 0.8604\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.8359 - val_loss: 0.4827 - val_accuracy: 0.8754\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.8401 - val_loss: 0.4760 - val_accuracy: 0.8429\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.8195 - val_loss: 0.4626 - val_accuracy: 0.8825\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8410 - val_loss: 0.4600 - val_accuracy: 0.8871\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.8755 - val_loss: 0.4449 - val_accuracy: 0.8250\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8673 - val_loss: 0.4327 - val_accuracy: 0.8604\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.8775 - val_loss: 0.4270 - val_accuracy: 0.8354\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.8683 - val_loss: 0.4185 - val_accuracy: 0.8300\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8537 - val_loss: 0.4071 - val_accuracy: 0.9104\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.9015 - val_loss: 0.3916 - val_accuracy: 0.9096\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.9048 - val_loss: 0.3793 - val_accuracy: 0.9171\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.9148 - val_loss: 0.3694 - val_accuracy: 0.9200\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.9138 - val_loss: 0.3602 - val_accuracy: 0.9350\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.9218 - val_loss: 0.3503 - val_accuracy: 0.9367\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.9257 - val_loss: 0.3387 - val_accuracy: 0.9417\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.9323 - val_loss: 0.3308 - val_accuracy: 0.9192\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.9312 - val_loss: 0.3200 - val_accuracy: 0.9404\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.9393 - val_loss: 0.3151 - val_accuracy: 0.9337\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3139 - accuracy: 0.9381 - val_loss: 0.3030 - val_accuracy: 0.9358\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3034 - accuracy: 0.9406 - val_loss: 0.2902 - val_accuracy: 0.9479\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2934 - accuracy: 0.9418 - val_loss: 0.2825 - val_accuracy: 0.9546\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2792 - accuracy: 0.9547 - val_loss: 0.2737 - val_accuracy: 0.9533\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2733 - accuracy: 0.9674 - val_loss: 0.2645 - val_accuracy: 0.9567\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2584 - accuracy: 0.9594 - val_loss: 0.2578 - val_accuracy: 0.9883\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2566 - accuracy: 0.9866 - val_loss: 0.2489 - val_accuracy: 0.9883\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.9823 - val_loss: 0.2405 - val_accuracy: 0.9912\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2421 - accuracy: 0.9904 - val_loss: 0.2326 - val_accuracy: 0.9908\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9910 - val_loss: 0.2257 - val_accuracy: 0.9917\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2268 - accuracy: 0.9905 - val_loss: 0.2186 - val_accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2179 - accuracy: 0.9969 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2138 - accuracy: 0.9989 - val_loss: 0.2049 - val_accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2028 - accuracy: 0.9986 - val_loss: 0.1986 - val_accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.9967 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1925 - accuracy: 0.9993 - val_loss: 0.1862 - val_accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.9975 - val_loss: 0.1745 - val_accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1702 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.1607 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1369 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.1349 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbaDkeIolIXo"
      },
      "source": [
        "# **Draw loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "D8E2D0H9YGXa",
        "outputId": "541cb8c2-d15c-4cad-ca22-d7533b3e07af"
      },
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# calculate validation accuracy\n",
        "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Validation accuracy = \", acc)\n",
        "print(\"Validation loss     = \", loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy =  1.0\n",
            "Validation loss     =  0.008953222073614597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEozdccBlNdR"
      },
      "source": [
        "# **Calculate accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujVxnlK_hJmz",
        "outputId": "f0af940c-ef94-4873-8223-d948bdce69ff"
      },
      "source": [
        "y_pred = np.round(model.predict(x_val)).astype(int)\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"   \",np.flipud(x_val[i,:,0]))\n",
        "  print(\" + \",np.flipud(x_val[i,:,1]))\n",
        "  print(\"--------------------------------\")\n",
        "  print(\"pred \",np.flipud(y_pred[i,:,0]))\n",
        "  print(\"true \",np.flipud(y_val[i,:,0]))\n",
        "  print(\"  \")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    [0 0 1 1 0 0 0 0]\n",
            " +  [0 0 0 1 0 0 0 1]\n",
            "--------------------------------\n",
            "pred  [0 1 0 0 0 0 0 1]\n",
            "true  [0 1 0 0 0 0 0 1]\n",
            "  \n",
            "    [0 1 0 0 1 0 1 1]\n",
            " +  [0 0 0 0 1 1 1 1]\n",
            "--------------------------------\n",
            "pred  [0 1 0 1 1 0 1 0]\n",
            "true  [0 1 0 1 1 0 1 0]\n",
            "  \n",
            "    [0 1 1 1 1 0 0 1]\n",
            " +  [0 1 1 0 0 1 0 1]\n",
            "--------------------------------\n",
            "pred  [1 1 0 1 1 1 1 0]\n",
            "true  [1 1 0 1 1 1 1 0]\n",
            "  \n",
            "    [0 0 0 0 1 0 1 1]\n",
            " +  [0 0 0 0 1 0 1 1]\n",
            "--------------------------------\n",
            "pred  [0 0 0 1 0 1 1 0]\n",
            "true  [0 0 0 1 0 1 1 0]\n",
            "  \n",
            "    [0 1 0 1 0 0 0 1]\n",
            " +  [0 1 1 1 1 0 1 1]\n",
            "--------------------------------\n",
            "pred  [1 1 0 0 1 1 0 0]\n",
            "true  [1 1 0 0 1 1 0 0]\n",
            "  \n",
            "    [0 1 1 0 0 1 1 0]\n",
            " +  [0 0 0 0 1 0 0 0]\n",
            "--------------------------------\n",
            "pred  [0 1 1 0 1 1 1 0]\n",
            "true  [0 1 1 0 1 1 1 0]\n",
            "  \n",
            "    [0 1 0 1 0 0 1 1]\n",
            " +  [0 1 1 1 0 1 0 1]\n",
            "--------------------------------\n",
            "pred  [1 1 0 0 1 0 0 0]\n",
            "true  [1 1 0 0 1 0 0 0]\n",
            "  \n",
            "    [0 0 1 1 0 1 0 0]\n",
            " +  [0 1 0 0 0 0 1 1]\n",
            "--------------------------------\n",
            "pred  [0 1 1 1 0 1 1 1]\n",
            "true  [0 1 1 1 0 1 1 1]\n",
            "  \n",
            "    [0 0 0 1 1 0 0 0]\n",
            " +  [0 1 1 1 1 1 1 0]\n",
            "--------------------------------\n",
            "pred  [1 0 0 1 0 1 1 0]\n",
            "true  [1 0 0 1 0 1 1 0]\n",
            "  \n",
            "    [0 0 1 1 1 1 0 0]\n",
            " +  [0 1 1 1 0 0 1 1]\n",
            "--------------------------------\n",
            "pred  [1 0 1 0 1 1 1 1]\n",
            "true  [1 0 1 0 1 1 1 1]\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}