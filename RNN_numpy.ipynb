{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "RNN_numpy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/DeepLearning_2020/blob/main/RNN_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfXFYpH2Mfir"
      },
      "source": [
        "# Recurrent Neural Network\n",
        "Numpy implementation of binary addition in RNN. \n",
        "Code from https://github.com/revsic/numpy-rnn/blob/master/RNN_numpy.ipynb \n",
        "This code is in turn based on [iamtrask's github.io](https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W36CcBiZzcn"
      },
      "source": [
        "The network is trained to add two binary numbers \n",
        "\n",
        "Input: binary a and b in the form of a vector of bins, ex. [1 1 1 1 0 1 1 0]\n",
        "\n",
        "Output: binary c - predicted result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8KUde5RBMfjE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZWYrP3MfjM"
      },
      "source": [
        "## Data Generation\n",
        "\n",
        "Generate the binary array less than 256."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gWvfLXeJMfjP"
      },
      "source": [
        "BIN_DIM = 8\n",
        "INPUT_DIM = 2\n",
        "HIDDEN_DIM = 16\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "ALPHA = 0.1\n",
        "ITER_NUM = 10000\n",
        "LOG_ITER = ITER_NUM // 10\n",
        "PLOT_ITER = ITER_NUM // 200"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaAmtxRQMfjX"
      },
      "source": [
        "largest = pow(2, BIN_DIM)\n",
        "decimal = np.array([range(largest)]).astype(np.uint8).T\n",
        "binary = np.unpackbits(decimal, axis=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q47lt8giMfje"
      },
      "source": [
        "## Prepare weights and deltas\n",
        "Prepare weight and delta values to use in the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMg1IHCMfjh"
      },
      "source": [
        "# weight values\n",
        "w0 = np.random.normal(0, 1, [INPUT_DIM, HIDDEN_DIM])\n",
        "w1 = np.random.normal(0, 1, [HIDDEN_DIM, OUTPUT_DIM])\n",
        "wh = np.random.normal(0, 2, [HIDDEN_DIM, HIDDEN_DIM])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5p8hN4Mfjm"
      },
      "source": [
        "# delta values\n",
        "d0 = np.zeros_like(w0)\n",
        "d1 = np.zeros_like(w1)\n",
        "dh = np.zeros_like(wh)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "opGi39SLMfjt"
      },
      "source": [
        "errs = list()\n",
        "accs = list()\n",
        "\n",
        "error = 0\n",
        "accuracy = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItfrBiHhMfju"
      },
      "source": [
        "## Training\n",
        "Training binary addition in RNN with Backpropagation Through Time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cks-r1JzMfjw"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(out):\n",
        "    return out * (1 - out)\n",
        "\n",
        "def bin2dec(b):\n",
        "    out = 0\n",
        "    for i, x in enumerate(b[::-1]):\n",
        "        out += x * pow(2, i)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZhfVYz1Mfj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24320fc-cc85-4050-9c65-326e63cb0754"
      },
      "source": [
        "for i in range(ITER_NUM + 1):\n",
        "    # a + b = c\n",
        "    a_dec = np.random.randint(largest / 2)\n",
        "    b_dec = np.random.randint(largest / 2)\n",
        "    c_dec = a_dec + b_dec\n",
        "    \n",
        "    a_bin = binary[a_dec]\n",
        "    b_bin = binary[b_dec]\n",
        "    c_bin = binary[c_dec]\n",
        "    \n",
        "    pred = np.zeros_like(c_bin)\n",
        "    \n",
        "    overall_err = 0 # total error in the whole calculation process.\n",
        "    \n",
        "    output_deltas = list()\n",
        "    hidden_values = list()\n",
        "    hidden_values.append(np.zeros(HIDDEN_DIM))\n",
        "    \n",
        "    future_delta = np.zeros(HIDDEN_DIM)\n",
        "    \n",
        "    # forward propagation\n",
        "    for pos in range(BIN_DIM)[::-1]:\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]]) # shape=(1, 2)\n",
        "        Y = np.array([[c_bin[pos]]]) # shape=(1, 1)\n",
        "        \n",
        "        hidden = sigmoid(np.dot(X, w0) + np.dot(hidden_values[-1], wh))\n",
        "        output = sigmoid(np.dot(hidden, w1))\n",
        "        \n",
        "        pred[pos] = np.round(output[0][0])\n",
        "        \n",
        "        # squared mean error\n",
        "        output_err = Y - output\n",
        "        output_deltas.append(output_err * deriv_sigmoid(output))\n",
        "        hidden_values.append(hidden)\n",
        "        \n",
        "        overall_err += np.abs(output_err[0])\n",
        "    \n",
        "    # backpropagation through time\n",
        "    for pos in range(BIN_DIM):\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]])\n",
        "        \n",
        "        hidden = hidden_values[-(pos + 1)]\n",
        "        prev_hidden = hidden_values[-(pos + 2)]\n",
        "        \n",
        "        output_delta = output_deltas[-(pos + 1)]\n",
        "        hidden_delta = (np.dot(future_delta, wh.T) + np.dot(output_delta, w1.T)) * deriv_sigmoid(hidden)\n",
        "        \n",
        "        d1 += np.dot(np.atleast_2d(hidden).T, output_delta)\n",
        "        dh += np.dot(np.atleast_2d(prev_hidden).T, hidden_delta)\n",
        "        d0 += np.dot(X.T, hidden_delta)\n",
        "\n",
        "        future_delta = hidden_delta \n",
        "    \n",
        "    w1 += ALPHA * d1\n",
        "    w0 += ALPHA * d0\n",
        "    wh += ALPHA * dh\n",
        "    \n",
        "    d1 *= 0\n",
        "    d0 *= 0\n",
        "    dh *= 0\n",
        "    \n",
        "    error += overall_err\n",
        "    if (bin2dec(pred) == c_dec):\n",
        "        accuracy += 1\n",
        "        \n",
        "    if (i % PLOT_ITER == 0):\n",
        "        errs.append(error / PLOT_ITER)\n",
        "        accs.append(accuracy / PLOT_ITER)\n",
        "        \n",
        "        error = 0\n",
        "        accuracy = 0\n",
        "    \n",
        "    if (i % LOG_ITER == 0):\n",
        "        print('Iter', i)\n",
        "        print(\"Error :\", overall_err)\n",
        "        print(\"Pred :\", pred)\n",
        "        print(\"True :\", c_bin)\n",
        "        print(a_dec, \"+\", b_dec, \"=\", bin2dec(pred))\n",
        "        print('----------')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0\n",
            "Error : [3.62159641]\n",
            "Pred : [1 1 1 1 0 1 0 0]\n",
            "True : [1 0 1 0 0 1 0 1]\n",
            "80 + 85 = 244\n",
            "----------\n",
            "Iter 1000\n",
            "Error : [3.85702386]\n",
            "Pred : [1 1 1 1 1 1 1 0]\n",
            "True : [1 1 1 0 0 1 1 1]\n",
            "110 + 121 = 254\n",
            "----------\n",
            "Iter 2000\n",
            "Error : [3.72886045]\n",
            "Pred : [1 0 1 0 1 1 0 1]\n",
            "True : [1 0 1 1 0 0 0 0]\n",
            "116 + 60 = 173\n",
            "----------\n",
            "Iter 3000\n",
            "Error : [3.94378592]\n",
            "Pred : [0 1 0 1 0 1 1 0]\n",
            "True : [0 1 1 0 0 1 0 1]\n",
            "38 + 63 = 86\n",
            "----------\n",
            "Iter 4000\n",
            "Error : [4.04873288]\n",
            "Pred : [1 0 1 1 1 1 0 1]\n",
            "True : [0 1 1 0 0 1 1 0]\n",
            "62 + 40 = 189\n",
            "----------\n",
            "Iter 5000\n",
            "Error : [3.45314363]\n",
            "Pred : [0 0 0 0 0 0 0 0]\n",
            "True : [0 0 1 1 0 0 0 0]\n",
            "36 + 12 = 0\n",
            "----------\n",
            "Iter 6000\n",
            "Error : [3.62812703]\n",
            "Pred : [0 1 1 0 0 0 0 0]\n",
            "True : [0 0 1 1 0 0 1 0]\n",
            "17 + 33 = 96\n",
            "----------\n",
            "Iter 7000\n",
            "Error : [3.25666253]\n",
            "Pred : [0 0 1 1 0 1 1 0]\n",
            "True : [0 0 1 0 1 0 1 0]\n",
            "20 + 22 = 54\n",
            "----------\n",
            "Iter 8000\n",
            "Error : [2.78532498]\n",
            "Pred : [1 0 0 1 0 0 1 1]\n",
            "True : [1 0 0 1 1 0 1 1]\n",
            "54 + 101 = 147\n",
            "----------\n",
            "Iter 9000\n",
            "Error : [2.04216527]\n",
            "Pred : [1 0 0 1 0 1 1 0]\n",
            "True : [1 0 0 1 0 1 1 0]\n",
            "115 + 35 = 150\n",
            "----------\n",
            "Iter 10000\n",
            "Error : [2.31773184]\n",
            "Pred : [0 1 0 0 1 0 1 1]\n",
            "True : [0 1 0 0 1 0 0 1]\n",
            "46 + 27 = 75\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIcQ6dxxMfkH"
      },
      "source": [
        "## Plot learning curve\n",
        "Plot error and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWTNNqqSMfkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "66d8e8fb-544a-4478-a08a-51134c499b18"
      },
      "source": [
        "plt.plot(errs, label='error')\n",
        "plt.plot(accs, label='accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f53bbc23630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3OkYcv8PzfR"
      },
      "source": [
        "Test the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Js4WPC6Px6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5235ef-5d8b-4ce9-9396-51263060e3dd"
      },
      "source": [
        "TEST_ITER_NUM = 10000\n",
        "\n",
        "n_yes = 0\n",
        "n_no  = 0\n",
        "\n",
        "for i in range(TEST_ITER_NUM + 1):\n",
        "    # a + b = c\n",
        "    # generate test data\n",
        "\n",
        "    a_dec = np.random.randint(largest / 2)\n",
        "    b_dec = np.random.randint(largest / 2)\n",
        "    c_dec = a_dec + b_dec\n",
        "    \n",
        "    a_bin = binary[a_dec]\n",
        "    b_bin = binary[b_dec]\n",
        "    c_bin = binary[c_dec]\n",
        "    \n",
        "    pred = np.zeros_like(c_bin)\n",
        "    \n",
        "    overall_err = 0 # total error in the whole calculation process.\n",
        "    \n",
        "    output_deltas = list()\n",
        "    hidden_values = list()\n",
        "    hidden_values.append(np.zeros(HIDDEN_DIM))\n",
        "    \n",
        "    future_delta = np.zeros(HIDDEN_DIM)\n",
        "    \n",
        "\n",
        "    # forward propagation\n",
        "    for pos in range(BIN_DIM)[::-1]:\n",
        "        X = np.array([[a_bin[pos], b_bin[pos]]]) # shape=(1, 2)\n",
        "        Y = np.array([[c_bin[pos]]]) # shape=(1, 1)\n",
        "        \n",
        "        hidden = sigmoid(np.dot(X, w0) + np.dot(hidden_values[-1], wh))\n",
        "        output = sigmoid(np.dot(hidden, w1))\n",
        "        \n",
        "        pred[pos] = np.round(output[0][0])\n",
        "\n",
        "        # squared mean error\n",
        "        output_err = Y - output\n",
        "        output_deltas.append(output_err * deriv_sigmoid(output))\n",
        "        hidden_values.append(hidden)\n",
        "        \n",
        "        overall_err += np.abs(output_err[0])        \n",
        "\n",
        "\n",
        "\n",
        "    # accuracy\n",
        "    if (bin2dec(pred) == c_dec): \n",
        "      n_yes += 1\n",
        "    else:\n",
        "      n_no  += 1\n",
        "    \n",
        "    if i<30:\n",
        "      print('Iter', i)\n",
        "      print(\"Error :\", overall_err)\n",
        "      print(\"Pred :\", pred)\n",
        "      print(\"True :\", c_bin)\n",
        "      print(a_dec, \"+\", b_dec, \"=\", bin2dec(pred))\n",
        "      print('----------')\n",
        "\n",
        "# calculate accuracy\n",
        "acc = float(n_yes)/float(n_yes+n_no)\n",
        "\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\" \")\n",
        "print(\"RNN accuracy = \",acc)\n",
        "print(\" \")\n",
        "print(\" \")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0\n",
            "Error : [2.15443852]\n",
            "Pred : [0 1 0 0 1 0 0 0]\n",
            "True : [0 1 0 0 1 1 0 0]\n",
            "71 + 5 = 72\n",
            "----------\n",
            "Iter 1\n",
            "Error : [1.11056858]\n",
            "Pred : [0 1 0 1 0 1 0 0]\n",
            "True : [0 1 0 1 0 1 0 0]\n",
            "14 + 70 = 84\n",
            "----------\n",
            "Iter 2\n",
            "Error : [1.4387215]\n",
            "Pred : [0 1 0 1 1 1 0 1]\n",
            "True : [0 1 0 1 1 1 0 1]\n",
            "51 + 42 = 93\n",
            "----------\n",
            "Iter 3\n",
            "Error : [2.47165375]\n",
            "Pred : [1 1 1 0 1 1 1 1]\n",
            "True : [1 0 1 0 1 1 0 1]\n",
            "50 + 123 = 239\n",
            "----------\n",
            "Iter 4\n",
            "Error : [3.24765043]\n",
            "Pred : [1 0 1 0 1 0 1 1]\n",
            "True : [1 0 0 1 1 1 1 1]\n",
            "123 + 36 = 171\n",
            "----------\n",
            "Iter 5\n",
            "Error : [1.68683572]\n",
            "Pred : [1 1 0 0 1 1 0 0]\n",
            "True : [1 1 0 0 1 1 0 0]\n",
            "104 + 100 = 204\n",
            "----------\n",
            "Iter 6\n",
            "Error : [2.42876581]\n",
            "Pred : [1 1 0 1 1 0 1 1]\n",
            "True : [1 1 0 1 0 1 1 1]\n",
            "104 + 111 = 219\n",
            "----------\n",
            "Iter 7\n",
            "Error : [3.67416697]\n",
            "Pred : [1 0 1 0 0 1 1 1]\n",
            "True : [1 0 0 1 1 1 1 1]\n",
            "76 + 83 = 167\n",
            "----------\n",
            "Iter 8\n",
            "Error : [1.65229147]\n",
            "Pred : [1 0 1 0 0 0 0 1]\n",
            "True : [1 0 1 0 0 0 0 1]\n",
            "116 + 45 = 161\n",
            "----------\n",
            "Iter 9\n",
            "Error : [1.1740789]\n",
            "Pred : [0 1 1 0 0 0 1 0]\n",
            "True : [0 1 1 0 0 0 1 0]\n",
            "94 + 4 = 98\n",
            "----------\n",
            "Iter 10\n",
            "Error : [1.53936349]\n",
            "Pred : [1 0 0 0 0 1 0 1]\n",
            "True : [1 0 0 0 0 1 0 1]\n",
            "45 + 88 = 133\n",
            "----------\n",
            "Iter 11\n",
            "Error : [1.91932678]\n",
            "Pred : [1 0 0 0 1 0 0 1]\n",
            "True : [1 0 0 0 1 0 0 1]\n",
            "45 + 92 = 137\n",
            "----------\n",
            "Iter 12\n",
            "Error : [1.42845518]\n",
            "Pred : [0 1 1 0 0 0 1 1]\n",
            "True : [0 1 1 0 0 0 1 1]\n",
            "88 + 11 = 99\n",
            "----------\n",
            "Iter 13\n",
            "Error : [2.49005349]\n",
            "Pred : [1 1 1 1 0 1 1 0]\n",
            "True : [0 1 1 1 0 1 1 0]\n",
            "99 + 19 = 246\n",
            "----------\n",
            "Iter 14\n",
            "Error : [1.62303336]\n",
            "Pred : [1 1 0 1 0 0 1 1]\n",
            "True : [1 1 0 1 0 0 1 1]\n",
            "124 + 87 = 211\n",
            "----------\n",
            "Iter 15\n",
            "Error : [2.29893651]\n",
            "Pred : [0 1 1 0 1 1 1 1]\n",
            "True : [0 1 1 0 0 1 1 1]\n",
            "12 + 91 = 111\n",
            "----------\n",
            "Iter 16\n",
            "Error : [3.94586691]\n",
            "Pred : [1 0 0 1 1 1 0 0]\n",
            "True : [0 1 1 1 1 1 1 0]\n",
            "49 + 77 = 156\n",
            "----------\n",
            "Iter 17\n",
            "Error : [1.90068253]\n",
            "Pred : [0 1 1 1 1 0 1 1]\n",
            "True : [0 0 1 1 1 0 1 1]\n",
            "17 + 42 = 123\n",
            "----------\n",
            "Iter 18\n",
            "Error : [1.86904151]\n",
            "Pred : [0 1 0 0 1 0 0 0]\n",
            "True : [0 1 0 0 1 0 0 0]\n",
            "20 + 52 = 72\n",
            "----------\n",
            "Iter 19\n",
            "Error : [2.20860773]\n",
            "Pred : [0 1 1 1 1 0 1 1]\n",
            "True : [0 1 1 0 1 1 1 1]\n",
            "71 + 40 = 123\n",
            "----------\n",
            "Iter 20\n",
            "Error : [1.37306977]\n",
            "Pred : [0 1 1 0 0 0 1 0]\n",
            "True : [0 1 1 0 0 0 1 0]\n",
            "15 + 83 = 98\n",
            "----------\n",
            "Iter 21\n",
            "Error : [2.75035006]\n",
            "Pred : [0 1 1 1 1 1 1 1]\n",
            "True : [0 1 1 1 1 1 0 1]\n",
            "2 + 123 = 127\n",
            "----------\n",
            "Iter 22\n",
            "Error : [2.06836874]\n",
            "Pred : [1 1 1 1 0 0 0 1]\n",
            "True : [0 1 1 1 0 0 0 1]\n",
            "0 + 113 = 241\n",
            "----------\n",
            "Iter 23\n",
            "Error : [1.43658623]\n",
            "Pred : [0 1 1 0 1 1 0 1]\n",
            "True : [0 1 1 0 1 1 0 1]\n",
            "8 + 101 = 109\n",
            "----------\n",
            "Iter 24\n",
            "Error : [1.80404714]\n",
            "Pred : [1 0 0 0 0 0 1 0]\n",
            "True : [1 0 0 0 0 0 1 0]\n",
            "40 + 90 = 130\n",
            "----------\n",
            "Iter 25\n",
            "Error : [2.33057822]\n",
            "Pred : [0 1 1 1 1 0 1 1]\n",
            "True : [0 1 1 1 0 1 1 1]\n",
            "56 + 63 = 123\n",
            "----------\n",
            "Iter 26\n",
            "Error : [2.19973142]\n",
            "Pred : [0 1 1 1 1 1 0 1]\n",
            "True : [0 1 0 1 1 1 0 1]\n",
            "1 + 92 = 125\n",
            "----------\n",
            "Iter 27\n",
            "Error : [1.25185616]\n",
            "Pred : [0 1 1 0 1 1 0 0]\n",
            "True : [0 1 1 0 1 1 0 0]\n",
            "44 + 64 = 108\n",
            "----------\n",
            "Iter 28\n",
            "Error : [1.91908822]\n",
            "Pred : [1 0 1 0 1 0 0 0]\n",
            "True : [1 0 1 0 1 1 0 0]\n",
            "97 + 75 = 168\n",
            "----------\n",
            "Iter 29\n",
            "Error : [2.3812508]\n",
            "Pred : [0 1 1 0 1 1 1 1]\n",
            "True : [0 1 1 0 1 1 0 1]\n",
            "58 + 51 = 111\n",
            "----------\n",
            " \n",
            " \n",
            " \n",
            "---------------------------------------------------\n",
            " \n",
            "RNN accuracy =  0.47185281471852814\n",
            " \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVfu6nca1fG0"
      },
      "source": [
        "# **Now training using keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHgY2YOR1iv_",
        "outputId": "f9f5a34a-4ef6-413c-b1e3-e227ef5d0962"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, TimeDistributed, Dense,SimpleRNN\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training dataset generation                            \n",
        "int2binary = {}                                    #Use to convert the input integer to a computer-operable binary number\n",
        "binary_dim = 8                                     #defined the length of the binary number = 8\n",
        "\n",
        "largest_number = pow(2,binary_dim)                         #  The maximum number that can be taken is =256 \n",
        "binary = np.unpackbits(\n",
        "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)            \n",
        "for i in range(largest_number):                                # one-one correspondence between binary numbers and decimal numbers\n",
        "    int2binary[i] = binary[i]\n",
        "\n",
        "x_train = []  \n",
        "y_train = []  \n",
        "for j in range(1000):          #Model iteration times, you can change it yourself\n",
        "    # generate a simple addition problem (a + b = c)\n",
        "    a_int = np.random.randint(largest_number/2) # int version #constrained initialization input addenda a value does not exceed 128\n",
        "    a = list(int2binary[a_int]) # binary encoding # Convert the addend a to the corresponding binary number\n",
        "    a.reverse()\n",
        "\n",
        "    b_int = np.random.randint(largest_number/2) # int version\n",
        "    b = list(int2binary[b_int]) # binary encoding\n",
        "    b.reverse()\n",
        "\n",
        "    c_int = a_int + b_int    # \n",
        "    c = list(int2binary[c_int])\n",
        "    c.reverse()  \n",
        "\n",
        "\n",
        "\n",
        "    tempx = np.hstack((np.array([a]).T,np.array([b]).T))\n",
        "\n",
        "    tempx = np.array(tempx.reshape(8,2))\n",
        "    tempy = np.array([c]).reshape((8,1))\n",
        "\n",
        "    x_train.append(tempx)\n",
        "    y_train.append(tempy)\n",
        "     \n",
        "    \n",
        "    \n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=0)\n",
        "print(x_train.shape)  \n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Example training data:\")\n",
        "print(np.flipud(x_train[0,:,0]),\" + \",np.flipud(x_train[0,:,1]),\" = \",np.flipud(y_train[0,:,0]))\n",
        "print(np.flipud(x_train[1,:,0]),\" + \",np.flipud(x_train[1,:,1]),\" = \",np.flipud(y_train[1,:,0]))\n",
        "print(np.flipud(x_train[2,:,0]),\" + \",np.flipud(x_train[2,:,1]),\" = \",np.flipud(y_train[2,:,0]))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700, 8, 2)\n",
            "(700, 8, 1)\n",
            "Example training data:\n",
            "[0 1 0 1 1 0 1 0]  +  [0 0 1 1 0 1 0 0]  =  [1 0 0 0 1 1 1 0]\n",
            "[0 1 0 1 0 1 1 1]  +  [0 1 0 0 0 1 0 1]  =  [1 0 0 1 1 1 0 0]\n",
            "[0 0 0 0 0 0 0 1]  +  [0 1 0 1 1 1 1 0]  =  [0 1 0 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZDBZvxmpE5"
      },
      "source": [
        "# **Define model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B4EoKUump-6",
        "outputId": "8135cc16-7427-4d79-a936-b38f54312ed7"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(128, input_shape=(8, 2),return_sequences=True,activation=\"sigmoid\"))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary() \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 8, 128)            16768     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 8, 1)              129       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 1)              0         \n",
            "=================================================================\n",
            "Total params: 16,897\n",
            "Trainable params: 16,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3qinYUxlDH1"
      },
      "source": [
        "# **Train the RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCCuEQgLYEdv",
        "outputId": "6b9481cd-2a82-4b77-8e41-af8148d9af16"
      },
      "source": [
        "history = model.fit(x_train, y_train, 32, 300,validation_data=(x_val, y_val)) \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.7428 - accuracy: 0.5023 - val_loss: 0.6981 - val_accuracy: 0.5117\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.7000 - accuracy: 0.4965 - val_loss: 0.6937 - val_accuracy: 0.5117\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5075 - val_loss: 0.6929 - val_accuracy: 0.5725\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5291 - val_loss: 0.6929 - val_accuracy: 0.4875\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5151 - val_loss: 0.6925 - val_accuracy: 0.4971\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5075 - val_loss: 0.6922 - val_accuracy: 0.4979\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5234 - val_loss: 0.6938 - val_accuracy: 0.5033\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.5296 - val_loss: 0.6915 - val_accuracy: 0.5362\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6915 - val_accuracy: 0.5246\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5318 - val_loss: 0.6910 - val_accuracy: 0.5521\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.5462 - val_loss: 0.6904 - val_accuracy: 0.5987\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5829 - val_loss: 0.6908 - val_accuracy: 0.5383\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5510 - val_loss: 0.6901 - val_accuracy: 0.5842\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5556 - val_loss: 0.6916 - val_accuracy: 0.4617\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.5301 - val_loss: 0.6910 - val_accuracy: 0.5517\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5637 - val_loss: 0.6897 - val_accuracy: 0.5583\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.5647 - val_loss: 0.6888 - val_accuracy: 0.5738\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5810 - val_loss: 0.6898 - val_accuracy: 0.5400\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5752 - val_loss: 0.6888 - val_accuracy: 0.5671\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5791 - val_loss: 0.6879 - val_accuracy: 0.5717\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5733 - val_loss: 0.6886 - val_accuracy: 0.5979\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5893 - val_loss: 0.6888 - val_accuracy: 0.5754\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.5775 - val_loss: 0.6881 - val_accuracy: 0.5500\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.5812 - val_loss: 0.6876 - val_accuracy: 0.5796\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5710 - val_loss: 0.6889 - val_accuracy: 0.5708\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5718 - val_loss: 0.6871 - val_accuracy: 0.5425\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6862 - accuracy: 0.5725 - val_loss: 0.6872 - val_accuracy: 0.5596\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5722 - val_loss: 0.6869 - val_accuracy: 0.5550\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.5847 - val_loss: 0.6900 - val_accuracy: 0.5171\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.5613 - val_loss: 0.6861 - val_accuracy: 0.5938\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6867 - accuracy: 0.5911 - val_loss: 0.6872 - val_accuracy: 0.5754\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5669 - val_loss: 0.6864 - val_accuracy: 0.5904\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.5906 - val_loss: 0.6902 - val_accuracy: 0.5479\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5519 - val_loss: 0.6877 - val_accuracy: 0.5700\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.5872 - val_loss: 0.6869 - val_accuracy: 0.5858\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.5889 - val_loss: 0.6862 - val_accuracy: 0.5933\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.6000 - val_loss: 0.6892 - val_accuracy: 0.5400\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.5659 - val_loss: 0.6863 - val_accuracy: 0.5675\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.5615 - val_loss: 0.6909 - val_accuracy: 0.5671\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5443 - val_loss: 0.6899 - val_accuracy: 0.5567\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.5675 - val_loss: 0.6867 - val_accuracy: 0.5821\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5964 - val_loss: 0.6874 - val_accuracy: 0.5683\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.5813 - val_loss: 0.6860 - val_accuracy: 0.5917\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.5974 - val_loss: 0.6864 - val_accuracy: 0.6062\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5740 - val_loss: 0.6856 - val_accuracy: 0.5913\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.5908 - val_loss: 0.6860 - val_accuracy: 0.5717\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.5854 - val_loss: 0.6858 - val_accuracy: 0.5933\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.6161 - val_loss: 0.6861 - val_accuracy: 0.5987\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6854 - accuracy: 0.5913 - val_loss: 0.6874 - val_accuracy: 0.5900\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5915 - val_loss: 0.6884 - val_accuracy: 0.5692\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5655 - val_loss: 0.6863 - val_accuracy: 0.5879\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.6079 - val_loss: 0.6856 - val_accuracy: 0.5971\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.6208 - val_loss: 0.6865 - val_accuracy: 0.5879\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.5768 - val_loss: 0.6924 - val_accuracy: 0.5233\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.5639 - val_loss: 0.6896 - val_accuracy: 0.5346\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6840 - accuracy: 0.5813 - val_loss: 0.6857 - val_accuracy: 0.6025\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5947 - val_loss: 0.6858 - val_accuracy: 0.6075\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5946 - val_loss: 0.6857 - val_accuracy: 0.5983\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5946 - val_loss: 0.6854 - val_accuracy: 0.5721\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.5842 - val_loss: 0.6876 - val_accuracy: 0.5546\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5764 - val_loss: 0.6852 - val_accuracy: 0.5913\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5901 - val_loss: 0.6848 - val_accuracy: 0.5983\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.5962 - val_loss: 0.6860 - val_accuracy: 0.5537\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5824 - val_loss: 0.6881 - val_accuracy: 0.5342\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.5840 - val_loss: 0.6846 - val_accuracy: 0.5983\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.5870 - val_loss: 0.6867 - val_accuracy: 0.5808\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5801 - val_loss: 0.6870 - val_accuracy: 0.5713\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.6002 - val_loss: 0.6850 - val_accuracy: 0.5346\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5875 - val_loss: 0.6845 - val_accuracy: 0.6008\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6818 - accuracy: 0.6106 - val_loss: 0.6841 - val_accuracy: 0.6062\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.6040 - val_loss: 0.6843 - val_accuracy: 0.6025\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.6082 - val_loss: 0.6842 - val_accuracy: 0.5967\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6811 - accuracy: 0.6103 - val_loss: 0.6841 - val_accuracy: 0.5979\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6819 - accuracy: 0.5727 - val_loss: 0.6852 - val_accuracy: 0.5546\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.6063 - val_loss: 0.6839 - val_accuracy: 0.5900\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.6134 - val_loss: 0.6851 - val_accuracy: 0.5833\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6847 - accuracy: 0.5758 - val_loss: 0.6834 - val_accuracy: 0.5962\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.6031 - val_loss: 0.6868 - val_accuracy: 0.5621\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5985 - val_loss: 0.6833 - val_accuracy: 0.5846\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5992 - val_loss: 0.6830 - val_accuracy: 0.5729\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6791 - accuracy: 0.6095 - val_loss: 0.6823 - val_accuracy: 0.6108\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.6064 - val_loss: 0.6820 - val_accuracy: 0.5913\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.6130 - val_loss: 0.6833 - val_accuracy: 0.5446\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5720 - val_loss: 0.6828 - val_accuracy: 0.5821\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5963 - val_loss: 0.6815 - val_accuracy: 0.5596\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6737 - accuracy: 0.6000 - val_loss: 0.6813 - val_accuracy: 0.5938\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6745 - accuracy: 0.6091 - val_loss: 0.6800 - val_accuracy: 0.6125\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.6204 - val_loss: 0.6801 - val_accuracy: 0.5967\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.6044 - val_loss: 0.6794 - val_accuracy: 0.6096\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6742 - accuracy: 0.6072 - val_loss: 0.6786 - val_accuracy: 0.5896\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6743 - accuracy: 0.6105 - val_loss: 0.6784 - val_accuracy: 0.6008\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.5919 - val_loss: 0.6773 - val_accuracy: 0.5962\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6747 - accuracy: 0.5998 - val_loss: 0.6774 - val_accuracy: 0.5546\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.5831 - val_loss: 0.6761 - val_accuracy: 0.5800\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6711 - accuracy: 0.5815 - val_loss: 0.6749 - val_accuracy: 0.5796\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6682 - accuracy: 0.5963 - val_loss: 0.6753 - val_accuracy: 0.5904\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.5667 - val_loss: 0.6771 - val_accuracy: 0.5596\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6720 - accuracy: 0.5732 - val_loss: 0.6734 - val_accuracy: 0.5629\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6687 - accuracy: 0.5789 - val_loss: 0.6714 - val_accuracy: 0.5888\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6107 - val_loss: 0.6710 - val_accuracy: 0.5704\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6670 - accuracy: 0.5631 - val_loss: 0.6688 - val_accuracy: 0.6000\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6632 - accuracy: 0.5848 - val_loss: 0.6669 - val_accuracy: 0.5883\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6613 - accuracy: 0.5786 - val_loss: 0.6665 - val_accuracy: 0.5946\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6579 - accuracy: 0.6121 - val_loss: 0.6642 - val_accuracy: 0.6042\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6580 - accuracy: 0.5914 - val_loss: 0.6627 - val_accuracy: 0.5863\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6573 - accuracy: 0.5893 - val_loss: 0.6618 - val_accuracy: 0.5871\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6524 - accuracy: 0.5924 - val_loss: 0.6590 - val_accuracy: 0.5850\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6550 - accuracy: 0.5837 - val_loss: 0.6604 - val_accuracy: 0.5713\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.5862 - val_loss: 0.6553 - val_accuracy: 0.5879\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6455 - accuracy: 0.6114 - val_loss: 0.6545 - val_accuracy: 0.5892\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6461 - accuracy: 0.5992 - val_loss: 0.6519 - val_accuracy: 0.5921\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.5901 - val_loss: 0.6480 - val_accuracy: 0.6050\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6441 - accuracy: 0.6000 - val_loss: 0.6464 - val_accuracy: 0.6112\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.6058 - val_loss: 0.6449 - val_accuracy: 0.5950\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6107 - val_loss: 0.6432 - val_accuracy: 0.5663\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6375 - accuracy: 0.5955 - val_loss: 0.6377 - val_accuracy: 0.6171\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6314 - accuracy: 0.6081 - val_loss: 0.6358 - val_accuracy: 0.6033\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.6196 - val_loss: 0.6336 - val_accuracy: 0.6112\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6249 - accuracy: 0.6290 - val_loss: 0.6294 - val_accuracy: 0.6292\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6421 - val_loss: 0.6248 - val_accuracy: 0.6433\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6370 - val_loss: 0.6237 - val_accuracy: 0.6192\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.6257 - val_loss: 0.6244 - val_accuracy: 0.6654\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.6718 - val_loss: 0.6148 - val_accuracy: 0.6421\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6108 - accuracy: 0.6436 - val_loss: 0.6124 - val_accuracy: 0.6629\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.6097 - accuracy: 0.6607 - val_loss: 0.6075 - val_accuracy: 0.6425\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.6641 - val_loss: 0.6029 - val_accuracy: 0.6542\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.6620 - val_loss: 0.5999 - val_accuracy: 0.6367\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.6685 - val_loss: 0.6001 - val_accuracy: 0.6567\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.6543 - val_loss: 0.5908 - val_accuracy: 0.6842\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.6742 - val_loss: 0.5848 - val_accuracy: 0.6517\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.6832 - val_loss: 0.5812 - val_accuracy: 0.6608\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5713 - accuracy: 0.6719 - val_loss: 0.5771 - val_accuracy: 0.6779\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.6656 - val_loss: 0.5736 - val_accuracy: 0.6629\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.6853 - val_loss: 0.5669 - val_accuracy: 0.6650\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.6909 - val_loss: 0.5732 - val_accuracy: 0.7308\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7230 - val_loss: 0.5585 - val_accuracy: 0.6600\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.6864 - val_loss: 0.5513 - val_accuracy: 0.6762\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7068 - val_loss: 0.5444 - val_accuracy: 0.7175\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7188 - val_loss: 0.5404 - val_accuracy: 0.7138\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5307 - accuracy: 0.7367 - val_loss: 0.5373 - val_accuracy: 0.7192\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7337 - val_loss: 0.5278 - val_accuracy: 0.6888\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7231 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7373 - val_loss: 0.5151 - val_accuracy: 0.7300\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7531 - val_loss: 0.5083 - val_accuracy: 0.7596\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7611 - val_loss: 0.5010 - val_accuracy: 0.7667\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4985 - accuracy: 0.7739 - val_loss: 0.4957 - val_accuracy: 0.7596\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7639 - val_loss: 0.4916 - val_accuracy: 0.7467\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7912 - val_loss: 0.4857 - val_accuracy: 0.7654\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7923 - val_loss: 0.4782 - val_accuracy: 0.7675\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7747 - val_loss: 0.4691 - val_accuracy: 0.7987\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7910 - val_loss: 0.4629 - val_accuracy: 0.8192\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8013 - val_loss: 0.4542 - val_accuracy: 0.8167\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.8144 - val_loss: 0.4468 - val_accuracy: 0.7979\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8326 - val_loss: 0.4393 - val_accuracy: 0.8062\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8338 - val_loss: 0.4356 - val_accuracy: 0.8025\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8244 - val_loss: 0.4277 - val_accuracy: 0.8462\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8439 - val_loss: 0.4199 - val_accuracy: 0.8662\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8417 - val_loss: 0.4109 - val_accuracy: 0.8587\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8446 - val_loss: 0.4038 - val_accuracy: 0.8408\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8533 - val_loss: 0.3987 - val_accuracy: 0.8792\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8730 - val_loss: 0.3882 - val_accuracy: 0.8546\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8601 - val_loss: 0.3807 - val_accuracy: 0.8617\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8666 - val_loss: 0.3753 - val_accuracy: 0.8692\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8675 - val_loss: 0.3671 - val_accuracy: 0.8825\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.8798 - val_loss: 0.3651 - val_accuracy: 0.8533\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8594 - val_loss: 0.3531 - val_accuracy: 0.8908\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8858 - val_loss: 0.3463 - val_accuracy: 0.8867\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8785 - val_loss: 0.3404 - val_accuracy: 0.8900\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.8850 - val_loss: 0.3337 - val_accuracy: 0.8908\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8874 - val_loss: 0.3254 - val_accuracy: 0.9025\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3233 - accuracy: 0.8956 - val_loss: 0.3208 - val_accuracy: 0.8946\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3222 - accuracy: 0.8886 - val_loss: 0.3176 - val_accuracy: 0.8938\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3129 - accuracy: 0.8933 - val_loss: 0.3113 - val_accuracy: 0.8950\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3070 - accuracy: 0.9006 - val_loss: 0.3011 - val_accuracy: 0.9087\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3021 - accuracy: 0.9048 - val_loss: 0.2928 - val_accuracy: 0.9121\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2924 - accuracy: 0.9206 - val_loss: 0.2871 - val_accuracy: 0.9417\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2935 - accuracy: 0.9292 - val_loss: 0.2849 - val_accuracy: 0.9108\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2881 - accuracy: 0.9102 - val_loss: 0.2772 - val_accuracy: 0.9125\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2713 - accuracy: 0.9330 - val_loss: 0.2676 - val_accuracy: 0.9542\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2666 - accuracy: 0.9517 - val_loss: 0.2615 - val_accuracy: 0.9488\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2643 - accuracy: 0.9530 - val_loss: 0.2568 - val_accuracy: 0.9525\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9559 - val_loss: 0.2493 - val_accuracy: 0.9721\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2513 - accuracy: 0.9619 - val_loss: 0.2442 - val_accuracy: 0.9529\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.9559 - val_loss: 0.2367 - val_accuracy: 0.9767\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2357 - accuracy: 0.9680 - val_loss: 0.2381 - val_accuracy: 0.9700\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9686 - val_loss: 0.2274 - val_accuracy: 0.9633\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2302 - accuracy: 0.9657 - val_loss: 0.2185 - val_accuracy: 0.9833\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.2162 - accuracy: 0.9750 - val_loss: 0.2149 - val_accuracy: 0.9800\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9825 - val_loss: 0.2077 - val_accuracy: 0.9862\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2081 - accuracy: 0.9842 - val_loss: 0.2026 - val_accuracy: 0.9996\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2014 - accuracy: 0.9884 - val_loss: 0.1982 - val_accuracy: 0.9950\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9903 - val_loss: 0.1926 - val_accuracy: 0.9871\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9837 - val_loss: 0.1855 - val_accuracy: 0.9887\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1837 - accuracy: 0.9950 - val_loss: 0.1799 - val_accuracy: 0.9996\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1769 - accuracy: 0.9999 - val_loss: 0.1755 - val_accuracy: 0.9996\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1742 - accuracy: 0.9997 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1678 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9996\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9996\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1467 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbaDkeIolIXo"
      },
      "source": [
        "# **Draw loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "D8E2D0H9YGXa",
        "outputId": "0d11d74b-3edb-4f19-948e-f9f1397bda8b"
      },
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# calculate validation accuracy\n",
        "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"Validation accuracy = \", acc)\n",
        "print(\"Validation loss     = \", loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU9d3+8fdnZrKShJCQDRIIq7Ip0BFB2RRBFAWpIqA+gkvRKlJrf7ZYW2utT10r6lOsUrSKVQFxAaoUUVFcMWHfISBLQsgGZCFkne/vjxk1YGIGmOTMTD6v68pFzpKZ++SEOydnFWMMSimlAp/N6gBKKaV8QwtdKaWChBa6UkoFCS10pZQKElroSikVJBxWvXHbtm1Nenq6VW+vlFIBac2aNYXGmIT6pllW6Onp6WRmZlr19kopFZBEZF9D03SXi1JKBQktdKWUChJa6EopFSQs24eulGrZqquryc7OpqKiwuoofik8PJzU1FRCQkK8/hotdKWUJbKzs4mOjiY9PR0RsTqOXzHGUFRURHZ2Np06dfL663SXi1LKEhUVFcTHx2uZ10NEiI+PP+W/XrTQlVKW0TJv2Ol8bwKu0DP3Huax/25Hb/urlFInCrhC35RTzD8+2U1BWaXVUZRSAS4qKsrqCD4VcIXePSkagKy8MouTKKWUfwm4Qu+W6P6NuitfC10p5RvGGO6991569+5Nnz59WLBgAQC5ubkMHTqUvn370rt3bz777DNqa2uZOnXq9/POmjXL4vQ/8Oq0RREZDTwD2IG5xphHT5o+C7jIMxgJJBpjYn0Z9DsJ0WHEhDvYmVfaFC+vlLLAn5duYevBEp++Zs92Mfzpyl5ezfv222+zfv16NmzYQGFhIeeddx5Dhw7l9ddf59JLL+X++++ntraW8vJy1q9fT05ODps3bwbg6NGjPs19JhotdBGxA7OBkUA2kCEiS4wxW7+bxxjz6zrz3wX0a4Ks370+3ZKidQtdKeUzn3/+OZMnT8Zut5OUlMSwYcPIyMjgvPPO4+abb6a6upqrrrqKvn370rlzZ/bs2cNdd93FmDFjGDVqlNXxv+fNFvoAIMsYswdAROYD44CtDcw/GfiTb+LVo/QQN9ne44H84U32Fkqp5uXtlnRzGzp0KKtWreK9995j6tSp3HPPPdx4441s2LCB5cuX8/zzz7Nw4UJeeuklq6MC3u1Dbw8cqDOc7Rn3IyLSEegEfNzA9GkikikimQUFBaea1W3tPK7I/TtjK5awKHM/5VU17lMYa6vhyN7Te02lVIs2ZMgQFixYQG1tLQUFBaxatYoBAwawb98+kpKS+MUvfsGtt97K2rVrKSwsxOVycfXVV/Pwww+zdu1aq+N/z9eX/k8CFhljauubaIyZA8wBcDqdp3ci+ZDf4DqQwYNZ86hY+gYlS1uRRwStbRXEmSOslx7kRXajIjyB2MQ0otskEG2r5HBtBGnFa0lo14HydhdiknoT66iC0Cjw5gT+imL3vDa7e/hYITjCIeyk054ObYKSg5A+BEIjT23ZdiyDzH/BZY9CXOdT+1ql1GkbP348X331Feeeey4iwuOPP05ycjKvvPIKTzzxBCEhIURFRTFv3jxycnK46aabcLlcADzyyCMWp/+BNHaBjogMAh40xlzqGb4PwBjzo6UQkXXAncaYLxt7Y6fTaU77ARfVxzm+/i32bs3AVVGCqSjmWGUNhyPS6Vu2ipiqfFqZYz/+MmMnRNy/a46aVsTKMY7Y2pAV3pvImmIia0vJI56KmI50rMqiMOosHO36EOKqpPvmpyiJ70ul8zY27cnhoqxHqLGHs7PrLSR2P4+UDX/HZQtF9n+JvaqUPHsyDL6HNm2TcbXrR2hoBLZWceCqAbHBwXWwdTG1lWXUnH8nYa3aYJ4biJQXYsJjkan/geQ+7uBH9sGeldDnWvcviQMZsOUdGPxrOLwHqsrcv0AcoY1/7wqzILaDd/Mq1YS2bdtGjx49rI7h1+r7HonIGmOMs775vSl0B7ATGAHkABnAdcaYLSfNdzbwX6CT8eIyzjMqdG9UlVOYt5+jhfkU19hJ4Ai7w3uxc99BepZ/Q9uiNWw8Fku7mmy6VW2l2N6GckcsCbV5JFYdYD8pdDQHv/8FsNeVRLot7/uXzzHxlJhW9LDtB6DChGDHRQmRPOKawkzbq7SV4hMi1WLDjuv74Wrs1Bob4VINQA027qz6FX8OnUcCR6jFjkvshFCD3dRwxB5PTXg8Ccd2uue3heFwuS+wOhbRHkk7j9C4NByOEDAuTPVxarLX4Ug6Gyk+AFGJsHEBpuOFyMiHoHUatGrr/uUiAkl9tOhVs9FCb5zPC93zApcDT+M+bfElY8z/ishDQKYxZolnngeBcGPMTG+CNnmhnwljQISa0kL2HMzDUVtObGoPCresJK+kgk7xkTja9cEWlcDRQ3s5sutrtte2J9TmIiaqFd179CXCVcaGrdtxHT1ATMVBykpLqDl2GJcjgjCboTiyA3vjLiQ+pIqEA8vJy89jXfj5XDDkEvL3baN33lIwNRSXlVNS6WJXaA/G2T5HKkv5xHUuu0077nQsZkHtcEpMKybbP6aj5JEiRdgwGBFqsbHTlcpZtmyKQxJJqs4mw9WdfrbdOHD/ojJiQ4znl0xEG0joAe36QnxXiGkH7Z0QVe/jC5U6I1rojWuSQm8Kfl3ofsQYQ0lFDa0j3PdELq+qoayihsoaF9HhDmw2ISu/jDCHja/3HKaiupaC0koqa1yAIT2+FZtyiln97WGGJLvonJ5Ozr5d5GWtpb0U0k6K2O5Ko0ZCGGlfR7fQIs6q3YnDVP+QISQSadvdvV8/rhP0+rm78Le8DSGR0Osqi747KpBpoTfuVAtd74fu50Tk+zIHiAx1EBl64mrr36ENAL3atfbyVbtz4PBF5JdWUlldS0huCUfLq9lUPYl5+4+QnVcAlWV0kDz62naTUnuEC4v2kXwkg9ZbFyOf/e3Elzv6EAy8E+z646SUlfR/YAuVFhdJWpz7LJwLurY9YZoxhsPHqr7/+HRnAb/ZWcDW3BLamBKuDM2kT2wVedE9Of/wEpwrHsD16ePYOgyCEX+ElHOtWCSlWjwtdPUjIkJ8VBjxUWEAnN85nt+OPpuj5VWs/vYwX+0+h7l7ijh+tJYPInuTWPIJI9jE+H2rCX1hGNLlYug4yL3VfqqnbiqlTpsWuvJabGQol/ZK5tJeySeM35XXlztfX8v/5k1geuhSJhzaQtzujyDjReh7HZw9Btr/zKLUSvlGVFQUZWU/vuVIQ+OtoIWuzli3pGjemzGEHYdKmbUinUe25zMmZjd/CFtG8uezkM+egvTBYFxw3QIIi7Y6slJBKeBun6v8U4jdRu/2rZk7xcmrtwwgO6Y/g7KnM9LxCmvix1B7ZD/s/wrengYH11sdV7VwM2fOZPbs2d8PP/jggzz55JOUlZUxYsQI+vfvT58+fVi8eLHXr+kPt+DVLXTlUyLCkG4JDO7alhVb83hnXQ4Tt15PbGQIL5/9Bb23zYId78PAO2DUwz/cSkG1bMtmum+b4UvJfdy30ajHxIkTufvuu7nzzjsBWLhwIcuXLyc8PJx33nmHmJgYCgsLGThwIGPHjvXq+Z7+cAteLXTVJESEUb2SGdUrma0HS/jdWxu5Yt15dIqYy4vpH9P56+egsgRG/S9ENMmt85VqUL9+/cjPz+fgwYMUFBTQpk0b0tLSqK6u5ve//z2rVq3CZrORk5NDXl4eycnJjb6mP9yCVwtdNbme7WJ4984L+XJ3IU9+sJOLt13Bk/Eurln3b9j8DvS7AQberjcka8ka2JJuShMmTGDRokUcOnSIiRMnAvDaa69RUFDAmjVrCAkJIT09nYqKijN6n+a8Ba/uQ1fNwm5z74p56/ZBPPrzPjxQOp4pIU/ybeLFmMyXYPZAyN1gdUzVgkycOJH58+ezaNEiJkyYAEBxcTGJiYmEhISwcuVK9u3b5/Xr+cMteHULXTUrh93GpAEd6NWuNX94N4qLdrdjVOoEni29h9C3b8N2wyJonWp1TNUC9OrVi9LSUtq3b09KSgoA119/PVdeeSV9+vTB6XRy9tlne/16/nALXr2Xi7KMMYY312Qza8VOupeuZk7oU4TY7dgG3w3DfqsHTIOc3sulcXovFxUwRIRrnWlc0z+VVbv6cN1bnbml8mUu//RRqD7mPgtGKeU13YeuLGezCcPPSuS56Vfx97j7mVc7Cr78P1j3mtXRlAooWujKbyTFhLPw9kF83PFuPq/tRe2SuzAvjoLnLtDnxQYpq3b5BoLT+d5ooSu/EhXm4J83DeK/vR7npepL2Vd0DFOwHda8bHU05WPh4eEUFRVpqdfDGENRURHh4eGn9HW6D135nRC7jb9MvJBZcQkM/ziLd2Kf4Zz1b2C/+I96oDSIpKamkp2dTUFBgdVR/FJ4eDipqad2xpcWuvJLIsI9o84iNS6SOe9eyD8cqzn4/HhSbpqH6JWlQSEkJIROnTpZHSOoeLXLRURGi8gOEckSkXqfGSoi14rIVhHZIiKv+zamaqmudabxm7t+zb+ip5GQ9znfzr3R/cxXpdSPNFroImIHZgOXAT2BySLS86R5ugH3ARcaY3oBdzdBVtVCdU2KYcqvH2dp4u10LvqU/Ut9cxGGUsHGmy30AUCWMWaPMaYKmA+MO2meXwCzjTFHAIwx+b6NqVo6m0247NaH+FAGkbr2CdgwH8r0x0ypurwp9PbAgTrD2Z5xdXUHuovIFyLytYiM9lVApb4TEeYgd/iTZLi6wzu3wZPdYOsSq2Mp5Td8ddqiA+gGDAcmA/8UkR8duRKRaSKSKSKZemRbnY5rL+zBk0mP8dvaOygLT8FkzLU6klJ+w5tCzwHS6gynesbVlQ0sMcZUG2O+BXbiLvgTGGPmGGOcxhhnQkLC6WZWLViYw87zUwaxP20sz5cORr79FA7vsTqWUn7Bm0LPALqJSCcRCQUmASf/nfsu7q1zRKQt7l0w+r9MNYn4qDDe+MVATN/rqTQh5L59v9WRlPILjRa6MaYGmA4sB7YBC40xW0TkIREZ65ltOVAkIluBlcC9xpiipgqtlIgwY/xQ3mp1LSnZ75P/9XyrIyllOb19rgpo2QVHKJw9il7swUyYR2ivMVZHUqpJ/dTtc/VeLiqgpSa0ofjnb7DF1QHboimwa4XVkZSyjBa6CnjDzunK4t5/Z3tte1zzr4f9X8OqJ6Bwl9XRlGpWWugqKNx9xQB+HfogBa5oav49AT5+GFa/YHUspZqVFroKCq0jQ/jz5CE8XnUNjqoS98i9n1sbSqlmpoWugsYFXdpy16/uZ0HsrbzFxVCwjW8277A6llLNRgtdBZX0xBh6XvMAr1UOBSBz1X8sTqRU89FCV0GnT2pr7r1pEqW2GM7JW0xVjcvqSEo1Cy10FZQGdU/hYO/bGSwb2PnNcqvjKNUstNBV0Go/agZ5pg1RX/xVH4qhWgQtdBW0oqKi+bLdTaQf20jJBr3Nrgp+WugqqPUZO52drvaELr0DDm2yOo5STUoLXQW1rinxLOn9DEdqQqmZe6n7KlKlgpQWugp6d151MfdEP0lhTQTVH/zZ6jhKNRktdBX0IkLtPHD9SF6vHUFI9pdQtNvqSEo1CS101SL0SIkh6vwbqTVC7opnrY6jVJPQQlctxo2XDmKpYyRJ21+hZu9XVsdRyue00FWLER5iJ/rKR8g1cRx5+x49N10FHS101aJcfG4XlsVPJaFkK0fXv2t1HKV8SgtdtSgiwsUTZ/CtSeb4fx8Cl97nRQUPrwpdREaLyA4RyRKRmfVMnyoiBSKy3vNxq++jKuUbnZNiWdf5dlIq93BIHy6tgkijhS4idmA2cBnQE5gsIj3rmXWBMaav52Ouj3Mq5VPDxt/GLpMKK/8KtTVWx1HKJ7zZQh8AZBlj9hhjqoD5wLimjaVU04qPiWT72XeRXH2AA5++bHUcpXzCm0JvDxyoM5ztGXeyq0Vko4gsEpE0n6RTqgkNv+omNtOF6M8eorokz+o4Sp0xXx0UXQqkG2POAVYAr9Q3k4hME5FMEcksKCjw0VsrdXqiI8IoHPEUEa5jHHzxBqipsjqSUmfEm0LPAepucad6xn3PGFNkjKn0DM4FflbfCxlj5hhjnMYYZ0JCwunkVcqnhg8Zzjvt7qFj8Tfkv3m31XGUOiPeFHoG0E1EOolIKDAJOOHm0iKSUmdwLLDNdxGValpjpvyW+fYrSdzxGmafXkGqAlejhW6MqQGmA8txF/VCY8wWEXlIRMZ6ZpshIltEZAMwA5jaVIGV8rXo8BDMRfeTY+IpX/o7vYJUBSwxFv3wOp1Ok5mZacl7K3Wy8qoanvjrffyJOdRe9xb27pdYHUmpeonIGmOMs75peqWoUkBkqIOeo2/joInjwH8esTqOUqdFC10pjwkDu7I+8WrSSzI5vG+r1XGUOmVa6ErV0WvMHVQbO3v+q/dMV4FHC12pOjqmd2Zt9EX0zl1E2SF9spEKLFroSp0kesxfcBkbh96+z+ooSp0SLXSlTtKzR08+jh5Lev4KKor2Wx1HKa9poStVj/Yjp2Mzhu1Ln7E6ilJe00JXqh79zu3LmoiBpO+dT/HRw1bHUcorWuhKNSB+9H3EUkbGm49bHUUpr2ihK9WAzn2HsSNqAP2z/03+4SKr4yjVKC10pX5CzKX3EyelbH73aaujKNUoLXSlfkJKn+Fsi3QyaN/zHNux0uo4Sv0kLXSlGvPzOWSbBHjrVqipbHx+pSyiha5UI3p07cKipBm0qiqkau0bVsdRqkFa6Ep5YcRlE9jkSqf8k1ngclkdR6l6aaEr5YUBneNZGT+Z2PK9bFo53+o4StVLC10pL02aMp1DtiSqP3ua41W1VsdR6ke00JXyUmJsFJXO2+nPDr5c+Z7VcZT6ES10pU5BhxHTKJFoIjNnY9XjG5VqiFeFLiKjRWSHiGSJyMyfmO9qETEiUu/z7pQKdBIWxd7O13F+1Wq2bdJn4ir/0mihi4gdmA1cBvQEJotIz3rmiwZ+Baz2dUil/EmXMb+mCgclH82yOopSJ/BmC30AkGWM2WOMqQLmA+Pqme8vwGNAhQ/zKeV3WsWlsCFxHOcdfZ+cjXr1qPIf3hR6e+BAneFsz7jviUh/IM0Y85NHikRkmohkikhmQUHBKYdVyl90mfgYB0nEvuROPS9d+Y0zPigqIjbgKeA3jc1rjJljjHEaY5wJCQln+tZKWaZt27bs6DGd5JocNn79gdVxlAK8K/QcIK3OcKpn3Heigd7AJyKyFxgILNEDoyrYDb7iRioJZe+n8/SMF+UXvCn0DKCbiHQSkVBgErDku4nGmGJjTFtjTLoxJh34GhhrjNFTAFRQC4+KJT/lIgZXfMrqHdlWx1Gq8UI3xtQA04HlwDZgoTFmi4g8JCJjmzqgUv4s8ZIZxEkZ+1Y8Z3UUpRCr/lR0Op0mM1M34lXg2//URYQX76Fwymf07NzB6jgqyInIGmNMvbu09UpRpc5Qm/GPEycl5L95j+5LV5bSQlfqDEV3Oo/tnaYw/PgKvlr9pdVxVAumha6UD5w9/vdUEkrhh3onRmUdLXSlfMARk8iRblcztuYDNrxwM+iuF2UBLXSlfCT5mifZmHAFA4ve5dMvvrA6jmqBtNCV8pWwKHpc9ygAaz98jfKqGosDqZZGC10pHwppk0ZZXG+GujL4eHu+1XFUC6OFrpSPRZ4zjn62LNZ+o2e8qOalha6Uj9kG3EqVLZIL9v+DrPxSq+OoFkQLXSlfi4yjeuB0LrFlMuvl16ms0dMYVfPQQleqCUQPm0FVWDw3lL7M4nU5jX+BUj6gha5UUwiLIuSi3zLIvpW1K9/G5dLz0lXT00JXqomI8ybKI9pxXdnLLNuUa3Uc1QJooSvVVBxhhI/6I+fYviVz2b+o1a101cS00JVqQrZzJ1Ia040byl9lSea3VsdRQU4LXammZLMTdcVf6WLLxbH8Xo5X6tWjqulooSvVxKT7KLJ7/ZIraz9k9eybcdW6rI6kgpQWulLNIPWaR9iQ9j8ML1nM5uVzrY6jgpQWulLNQYReU55mu60r7TMewVQdszqRCkJeFbqIjBaRHSKSJSIz65l+u4hsEpH1IvK5iPT0fVSlApvD4eDQgPuIN4dZs/zfVsdRQajRQhcROzAbuAzoCUyup7BfN8b0Mcb0BR4HnvJ5UqWCwJCR48m3JVC59g1KK6qtjqOCjDdb6AOALGPMHmNMFTAfGFd3BmNMSZ3BVoCecKtUPex2O67e13C+awNLv1hvdRwVZLwp9PbAgTrD2Z5xJxCRO0VkN+4t9Bn1vZCITBORTBHJLCgoOJ28SgW85KG34hAXlV/9Uy82Uj7ls4OixpjZxpguwO+APzQwzxxjjNMY40xISPDVWysVWNp2JT95GFdWL+MfH26xOo0KIt4Ueg6QVmc41TOuIfOBq84klFLBLmH0b2krJbhWPck33x62Oo4KEt4UegbQTUQ6iUgoMAlYUncGEelWZ3AMsMt3EZUKPpI+mJreE/ilYynrFzxMjd4zXflAo4VujKkBpgPLgW3AQmPMFhF5SETGemabLiJbRGQ9cA8wpckSKxUkHJc/ztHkC5lW8SLLF/7D6jgqCIgx1hyUcTqdJjMz05L3VspvuFwcerQvhyvA/svPOSslxupEys+JyBpjjLO+aXqlqFJWstmIvuT/0dO2j68+fMvqNCrAaaErZbFW/a7lmC2axN1vcrxK96Wr06eFrpTVQsIp634VI8w3vPKxXmykTp8WulJ+IGn4bYRJNbYvZpGVX2p1HBWgtNCV8gfJfTjeazI32d/nHwuW6EOl1WnRQlfKT0Rc/jA1YXFML/gzb3651eo4KgBpoSvlL1q1Jfy6eXSy5VG04inySiqsTqQCjBa6Un5EOl7Asc6juZ5lzP1QD5CqU6OFrpSfaXXJfURLOV3XP0Zu8XGr46gAooWulL9p15cy53Qm2j5m8aJXrU6jAogWulJ+KGb0AxSHpTBg3wtsXv0RuPSCI9U4LXSl/JEjlIjh99DflkXvZT/n+NdzrU6kAoAWulJ+KvS8KeT2u5v9JpFvV77CscoaqyMpP6eFrpS/coSRMu7PVPSaRM/qLTy3eJXViZSf00JXys91HzEVANfGBaw/cNTSLMq/aaEr5e/iu1DTYTA3OD7in5/utDqN8mNa6EoFAMeAW2hPAa22v0XOUT03XdVPC12pQNDjSirbDeCv9jm8ueBVrHrSmPJvWuhKBQJ7CGFT3uFYZDtG5vydNzMOWJ1I+SGvCl1ERovIDhHJEpGZ9Uy/R0S2ishGEflIRDr6PqpSLVxYFNGj7qeXbR9rlr3I4WNVVidSfqbRQhcROzAbuAzoCUwWkZ4nzbYOcBpjzgEWAY/7OqhSCmznXEtFwrnc5/onzy3+xOo4ys94s4U+AMgyxuwxxlQB84FxdWcwxqw0xpR7Br8GUn0bUykFgN1B+KR/EWE3jNz+R77Oyrc6kfIj3hR6e6DuDrtsz7iG3AIsq2+CiEwTkUwRySwoKPA+pVLqB/Fd4Iq/cb5tOxvf+AP5pXrfdOXm04OiInID4ASeqG+6MWaOMcZpjHEmJCT48q2ValHC+l/H0W5Xc0vNQl55Y4HVcZSf8KbQc4C0OsOpnnEnEJFLgPuBscaYSt/EU0o1JPaaZygPT2RE9rN8ukN3vSjvCj0D6CYinUQkFJgELKk7g4j0A17AXeb6k6VUcwiLJnzETPrbslj65r8oPl5tdSJlsUYL3RhTA0wHlgPbgIXGmC0i8pCIjPXM9gQQBbwpIutFZEkDL6eU8qGQn/0PFa07M6N6Lo8szrQ6jrKYWHXFmdPpNJmZ+gOo1Bnb9yX86zIW1Q4l6toXGN2nndWJVBMSkTXGGGd90/RKUaUCXccLqB36O66xr2Lj24/pWS8tmBa6UkHAftF9HEsfyQzXazw9/32910sLpYWuVDAQodXVsyE0kqkH/sCCzzdbnUhZQAtdqWARnUTopFfpbDtE4ooZfLFLL95rabTQlQoiti7DqLnkL1xsW8vaN/5EYZleEtKSaKErFWTCL7yDki5XcpfrNV6f+zcqa2qtjqSaiRa6UsFGhJjJL1IY15+pR57lqUUrrU6kmokWulLByBFG2xteJNxuuHjr/Xy0SR+I0RJooSsVrOI6I1c+w/m27ZS8NZ2svBKrE6kmpoWuVBAL6TeJkgG/ZjyfsGLu/RTpQdKgpoWuVJCLGf0ARzqN4baqV5n7z2epqNaDpMFKC12pYGez0ea6FymOO4cZRx/n2X+/qVeSBiktdKVagpAI2tz8JjXhcdy4dyazl3ympR6EtNCVaimik4i6aRFt7BWMWHMHTy3+Wks9yGihK9WCSHIfQq6bT1d7HiPX/pLnlq2xOpLyIS10pVoYW9fh2Cf9m572Awz6+jZe+niT1ZGUj2ihK9UC2c66FJnwL8617aH7ytuY/+UuqyMpH9BCV6qFsvccixk7m8H2LSQs+wVL1+yxOpI6Q1roSrVgjv7XUXXZU4ywryN28Y18tHGv1ZHUGfCq0EVktIjsEJEsEZlZz/ShIrJWRGpE5Brfx1RKNZXQ82/h+OXPcqFtM1GLJvH2V9utjqROU6OFLiJ2YDZwGdATmCwiPU+abT8wFXjd1wGVUk0vYsAUKsc+j9O2g87LJvP8fz7XUxoDkDdb6AOALGPMHmNMFTAfGFd3BmPMXmPMRsDVBBmVUs0gov8kzLWv0sORy/iM63n65df0XuoBxptCbw/UvfdmtmfcKRORaSKSKSKZBQX6eCyl/I2j5xWETvuQ8IhW3LH3V7z094cpLq+2OpbyUrMeFDXGzDHGOI0xzoSEhOZ8a6WUlyS5N61nfE5x4nn88uhTfDRrCgcKiq2OpbzgTaHnAGl1hlM945RSwSoyjsTb/0Nuj5v5efV7HJp9OV9t2mF1KtUIbwo9A+gmIp1EJBSYBCxp2lhKKcvZHaRMnEXeiKc5lx2kLhrDv9/9D7UuPVjqrxotdGNMDTAdWA5sAxYaY7aIyEMiMhZARM4TkWxgAvCCiGxpytBKqeaTNOQmXFPfIybEcM26qbz+zO84eOSY1bFUPcSqU5OcTgQoCXIAAAmiSURBVKfJzMy05L2VUqfOlB7i4KvTaJ//KRmmB7kX/Y0rh12AiFgdrUURkTXGGGd90/RKUaWUVyQ6mfa/XMzhS2bRy7aPESvHM+/ZP5J7pMzqaMpDC10p5T0R4gbfTPiM1ZS07ceUI/9H6dODeO/teVRU1VidrsXTQldKnTJbmw6kTP8vBaNfIDakmjEb72LToxezatVHeoWphbTQlVKnR4SEgZNInLmBPT/7A2eZPQz+6Go+eexqNm/V8yKsoIWulDozjjA6X3kvre7dxI4uU7mgYhVdFwzjg2fvYPd+vWSlOWmhK6V8wh7Zhh43Pk3NHRnsSbyEUYdfo82LA1jyzAw27ciyOl6LoKctKqWaRPGeDAqXPkiXI59TYUL4NHIk4QNv5YLBFxFi123J0/VTpy1qoSulmtSxnC1kv/8k6TlLCaOardKFvC7X0mPUzSQnJlodL+BooSulLOc6dpisj14kfNNrdKj+lnITxurIYVSf+z8MGHIpsa3CrI4YELTQlVL+wxhyt35B0Wdz6XxoGZFUcMi0YWf0QMJ6XU6vwWOJio61OqXf0kJXSvklU1lKzpcLKd30HmmHvyKKcqqMg+0R51KRfgkdBv2c5I5nWx3Tr2ihK6X8nqu6ih0ZH1C84T+0y19FB+M+5XGfLZX98UNwnD2a7s4RxLeOtjiptbTQlVIBZ1/WZnJWv0vMgY/ofnwjoVJDpQlhl6MbRXH9sKcPol2fYaSnpmGztZwbhGmhK6UCWvXxEvZnLqN0x6dE5a+hY+UuQsT9vNMDJJEX0YXKuJ6EpZ5DQjcnqZ3Oxm63W5y6aWihK6WCiquynJytX3Jkx2dI7gZiS3fRvjYHm7j7rMxEcCAknaMxZ1HdtieR7XuR2PEs2qV2wuFwWJz+zGihK6WCXuXxUnJ2rOXw7rW4Dm0mung7aVV7iKL8+3mqjIM8exLFYe043ioVV+s0HG07E5nUhbbtuxHfNgmbn1/09FOFHti/qpRSyiMsIprOfYfRue+wH0YaQ8mhPeTt3UzJwV1UF+7FUbKf6IocUsu3EVtYBrt/mL3URJBrS6Y4LJnqiESISsLeOoWQ1ilExLUnum17Wie0Iyoi3C8f7KGFrpQKXiLEpHQhJqVLvZNLig9TdGAnJblZVBd+ixzdR1jZARIrc4k5soU2R0rgwIlf4zJCETGU2GIot8dQERJLTVgsrog4JDIeR1Q8jugEQqPiiWgdT2RMPNGt44mMbIXYmnbrXwtdKdVixbSOI6b1QOg9sN7p1VUVFOVlc6wwh/LDOVQfzcWU5mI7VoC94jChVUdpW5VN1PGtxBwpIdRzoLY+VcZBqbTimLQi33kPzjG/8PnyeFXoIjIaeAawA3ONMY+eND0MmAf8DCgCJhpj9vo2qlJKNa+Q0HCS07pCWtdG5zUuF2VlRykuzOd4cT4VJQVUHztCzbGjuI4fxVQUY6ssxl5VQnh0QpPkbbTQRcQOzAZGAtlAhogsMcZsrTPbLcARY0xXEZkEPAZMbIrASinlj8RmIyomjqiYOMCaq1u92aEzAMgyxuwxxlQB84FxJ80zDnjF8/kiYIT44xEDpZQKYt4UentOPCyQ7RlX7zzGmBqgGIg/+YVEZJqIZIpIZkFBweklVkopVa9mPeHSGDPHGOM0xjgTEppmH5JSSrVU3hR6DpBWZzjVM67eeUTEAbTGfXBUKaVUM/Gm0DOAbiLSSURCgUnAkpPmWQJM8Xx+DfCxseoSVKWUaqEaPcvFGFMjItOB5bhPW3zJGLNFRB4CMo0xS4AXgVdFJAs4jLv0lVJKNSOvzkM3xrwPvH/SuAfqfF4BTPBtNKWUUqfCv+9Co5RSymuW3W1RRAqAfaf55W2BQh/GsZIui3/SZfFPuizQ0RhT72mClhX6mRCRzIZuHxlodFn8ky6Lf9Jl+Wm6y0UppYKEFrpSSgWJQC30OVYH8CFdFv+ky+KfdFl+QkDuQ1dKKfVjgbqFrpRS6iRa6EopFSQCrtBFZLSI7BCRLBGZaXWeUyUie0Vkk4isF5FMz7g4EVkhIrs8/7axOmd9ROQlEckXkc11xtWbXdye9aynjSLS37rkP9bAsjwoIjmedbNeRC6vM+0+z7LsEJFLrUn9YyKSJiIrRWSriGwRkV95xgfcevmJZQnE9RIuIt+IyAbPsvzZM76TiKz2ZF7guT8WIhLmGc7yTE8/rTc2xgTMB+57yewGOgOhwAagp9W5TnEZ9gJtTxr3ODDT8/lM4DGrczaQfSjQH9jcWHbgcmAZIMBAYLXV+b1YlgeB/1fPvD09P2thQCfPz6Dd6mXwZEsB+ns+jwZ2evIG3Hr5iWUJxPUiQJTn8xBgtef7vRCY5Bn/PPBLz+d3AM97Pp8ELDid9w20LXRvnp4UiOo+8ekV4CoLszTIGLMK983X6moo+zhgnnH7GogVkZTmSdq4BpalIeOA+caYSmPMt0AW7p9Fyxljco0xaz2flwLbcD9wJuDWy08sS0P8eb0YY0yZZzDE82GAi3E/1Q1+vF7O+KlvgVbo3jw9yd8Z4AMRWSMi0zzjkowxuZ7PDwFJ1kQ7LQ1lD9R1Nd2zK+KlOru+AmJZPH+m98O9NRjQ6+WkZYEAXC8iYheR9UA+sAL3XxBHjfupbnBiXq+e+taYQCv0YDDYGNMfuAy4U0SG1p1o3H9zBeS5pIGc3eMfQBegL5AL/M3aON4TkSjgLeBuY0xJ3WmBtl7qWZaAXC/GmFpjTF/cDwUaQDM8OTrQCt2bpyf5NWNMjufffOAd3Cs677s/ez3/5luX8JQ1lD3g1pUxJs/zn9AF/JMf/nz362URkRDcBfiaMeZtz+iAXC/1LUugrpfvGGOOAiuBQbh3cX132/K6eX3y1LdAK3Rvnp7kt0SklYhEf/c5MArYzIlPfJoCLLYm4WlpKPsS4EbPWRUDgeI6uwD80kn7ksfjXjfgXpZJnjMROgHdgG+aO199PPtZXwS2GWOeqjMp4NZLQ8sSoOslQURiPZ9HACNxHxNYifupbvDj9XLmT32z+mjwaRw9vhz30e/dwP1W5znF7J1xH5XfAGz5Lj/ufWUfAbuAD4E4q7M2kP8N3H/yVuPe/3dLQ9lxH+Wf7VlPmwCn1fm9WJZXPVk3ev6DpdSZ/37PsuwALrM6f51cg3HvTtkIrPd8XB6I6+UnliUQ18s5wDpP5s3AA57xnXH/0skC3gTCPOPDPcNZnumdT+d99dJ/pZQKEoG2y0UppVQDtNCVUipIaKErpVSQ0EJXSqkgoYWulFJBQgtdKaWChBa6UkoFif8P3ej6SyRq5t4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy =  1.0\n",
            "Validation loss     =  0.010205252096056938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEozdccBlNdR"
      },
      "source": [
        "# **Calculate accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujVxnlK_hJmz",
        "outputId": "b1a3edac-3ab6-40d5-c6d7-f510e023af56"
      },
      "source": [
        "y_pred = np.round(model.predict(x_val)).astype(int)\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"   \",np.flipud(x_val[i,:,0]))\n",
        "  print(\" + \",np.flipud(x_val[i,:,1]))\n",
        "  print(\"--------------------------------\")\n",
        "  print(\"pred \",np.flipud(y_pred[i,:,0]))\n",
        "  print(\"true \",np.flipud(y_val[i,:,0]))\n",
        "  print(\"  \")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    [0 1 1 0 1 1 1 0]\n",
            " +  [0 1 0 1 0 1 1 1]\n",
            "--------------------------------\n",
            "pred  [1 1 0 0 0 1 0 1]\n",
            "true  [1 1 0 0 0 1 0 1]\n",
            "  \n",
            "    [0 1 0 0 0 1 1 1]\n",
            " +  [0 1 1 1 1 0 0 0]\n",
            "--------------------------------\n",
            "pred  [1 0 1 1 1 1 1 1]\n",
            "true  [1 0 1 1 1 1 1 1]\n",
            "  \n",
            "    [0 0 0 1 1 0 1 0]\n",
            " +  [0 0 1 1 0 0 0 0]\n",
            "--------------------------------\n",
            "pred  [0 1 0 0 1 0 1 0]\n",
            "true  [0 1 0 0 1 0 1 0]\n",
            "  \n",
            "    [0 0 1 1 0 0 0 0]\n",
            " +  [0 0 0 1 0 0 0 1]\n",
            "--------------------------------\n",
            "pred  [0 1 0 0 0 0 0 1]\n",
            "true  [0 1 0 0 0 0 0 1]\n",
            "  \n",
            "    [0 0 1 0 1 1 0 0]\n",
            " +  [0 1 0 0 1 1 1 1]\n",
            "--------------------------------\n",
            "pred  [0 1 1 1 1 0 1 1]\n",
            "true  [0 1 1 1 1 0 1 1]\n",
            "  \n",
            "    [0 1 0 0 0 1 0 0]\n",
            " +  [0 0 1 0 1 1 1 0]\n",
            "--------------------------------\n",
            "pred  [0 1 1 1 0 0 1 0]\n",
            "true  [0 1 1 1 0 0 1 0]\n",
            "  \n",
            "    [0 0 0 0 1 1 1 0]\n",
            " +  [0 0 0 1 0 1 1 1]\n",
            "--------------------------------\n",
            "pred  [0 0 1 0 0 1 0 1]\n",
            "true  [0 0 1 0 0 1 0 1]\n",
            "  \n",
            "    [0 1 0 0 0 1 1 1]\n",
            " +  [0 1 1 0 0 0 0 1]\n",
            "--------------------------------\n",
            "pred  [1 0 1 0 1 0 0 0]\n",
            "true  [1 0 1 0 1 0 0 0]\n",
            "  \n",
            "    [0 0 0 1 1 1 1 1]\n",
            " +  [0 0 1 0 1 1 1 0]\n",
            "--------------------------------\n",
            "pred  [0 1 0 0 1 1 0 1]\n",
            "true  [0 1 0 0 1 1 0 1]\n",
            "  \n",
            "    [0 1 1 1 1 1 1 1]\n",
            " +  [0 1 1 0 0 1 0 1]\n",
            "--------------------------------\n",
            "pred  [1 1 1 0 0 1 0 0]\n",
            "true  [1 1 1 0 0 1 0 0]\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}